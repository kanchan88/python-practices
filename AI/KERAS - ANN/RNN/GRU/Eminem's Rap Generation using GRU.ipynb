{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eminem's Rap Generation Using RNN\n",
    "\n",
    "RNN is one of the very powerful deep-learning algorithm which works amazingly well on Sequential Data. As historical or past data plays major role in the prediction of sequential data, RNN takes these inputs of not only recent output but also past output.\n",
    "\n",
    "## What is RNN?\n",
    "Recurrent Neural Network is a generalization of feedforward neural network that has an internal memory. RNN is recurrent in nature as it performs the same function for every input of data while the output of the current input depends on the past one computation. After producing the output, it is copied and sent back into the recurrent network. For making a decision, it considers the current input and the output that it has learned from the previous input.\n",
    "\n",
    "## What's the Data?\n",
    "\n",
    "I simply copied the eminem's Rap God Lyrics and pasted in eminem.txt. It has only 7855 characters which is very few. You need minimum of million data for realistic predictions. However, this is just a test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = \"eminem.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path_to_file, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(text[7854:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '2',\n",
       " '4',\n",
       " '7',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing \n",
    "\n",
    "1. Vectorizing\n",
    "2. Econding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pair in enumerate(vocab):\n",
    "#     print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we iterate in whole text and assigned the number for each \n",
    "#character using from char_to_ind \n",
    "\n",
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Look, I was gonna go easy on you and not to hurt y'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = text[:50]\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 53, 53, 49,  7,  1, 24,  1, 60, 39, 56,  1, 45, 53, 52, 52, 39,\n",
       "        1, 45, 53,  1, 43, 39, 56, 62,  1, 53, 52,  1, 62, 53, 58,  1, 39,\n",
       "       52, 42,  1, 52, 53, 57,  1, 57, 53,  1, 46, 58, 55, 57,  1, 62])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Batches\n",
    "\n",
    "1. Text Sequences\n",
    "2. Shuddle and Generate Batches using TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Look, I was gonna go easy on you and not to hurt your feelings\n",
      "But I'm only going to get this one chance\n",
      "Something's wrong, I can feel it (Six minutes, Slim Shady, you're on)\n",
      "Just a feeling I've got, like something's about to happen, but I don't know what\n",
      "If that means, what I think it means, we're in trouble, big trouble,\n",
      "And if he is as bananas as you say, I'm not taking any chances\n",
      "You were just what the doctor ordered\n",
      "I'm beginning to feel like a Rap God, Rap God\n",
      "All my people from the front\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = \"Look, I was gonna go easy on you and not to hurt your feelings\"\n",
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = \"\"\"\n",
    "Look, I was gonna go easy on you and not to hurt your feelings\n",
    "But I'm only going to get this one chance\n",
    "Something's wrong, I can feel it (Six minutes, Slim Shady, you're on)\n",
    "Just a feeling I've got, like something's about to happen, but I don't know what\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Look, I was gonna go easy on you and not to hurt your feelings\n",
      "But I'm only going to get this one chance\n",
      "Something's wrong, I can feel it (Six minutes, Slim Shady, you're on)\n",
      "Just a feeling I've got, like something's about to happen, but I don't know what\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_seq = len(text)//(seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1404"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create training sequences\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converts into sequence we can feed in as batch\n",
    "# for item in char_dataset.take(500):\n",
    "#     print(ind_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1, drop_remainder= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1] #look i am gonn\n",
    "    target_txt = seq[1:] #ook i am gonna\n",
    "    return input_txt, target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27 53 53 49  7  1 24  1 60 39 56  1 45 53 52 52 39  1 45 53  1 43 39 56\n",
      " 62  1 53 52  1 62 53 58  1 39 52 42  1 52 53 57  1 57 53  1 46 58 55 57\n",
      "  1 62 53 58 55  1 44 43 43 50 47 52 45 56  0 17 58 57  1 24  4 51  1 53\n",
      " 52 50 62  1 45 53 47 52 45  1 57 53  1 45 43 57  1 57 46 47 56  1 53 52\n",
      " 43  1 41 46 39 52 41 43  0 33 53 51 43 57 46 47 52 45  4 56  1 60 55 53\n",
      " 52 45  7  1 24  1 41 39 52  1 44 43 43 50  1 47 57  1  5 33 47 61  1 51\n",
      " 47 52 58 57 43 56]\n",
      "Look, I was gonna go easy on you and not to hurt your feelings\n",
      "But I'm only going to get this one chance\n",
      "Something's wrong, I can feel it (Six minutes\n",
      "\n",
      "\n",
      "[53 53 49  7  1 24  1 60 39 56  1 45 53 52 52 39  1 45 53  1 43 39 56 62\n",
      "  1 53 52  1 62 53 58  1 39 52 42  1 52 53 57  1 57 53  1 46 58 55 57  1\n",
      " 62 53 58 55  1 44 43 43 50 47 52 45 56  0 17 58 57  1 24  4 51  1 53 52\n",
      " 50 62  1 45 53 47 52 45  1 57 53  1 45 43 57  1 57 46 47 56  1 53 52 43\n",
      "  1 41 46 39 52 41 43  0 33 53 51 43 57 46 47 52 45  4 56  1 60 55 53 52\n",
      " 45  7  1 24  1 41 39 52  1 44 43 43 50  1 47 57  1  5 33 47 61  1 51 47\n",
      " 52 58 57 43 56  7]\n",
      "ook, I was gonna go easy on you and not to hurt your feelings\n",
      "But I'm only going to get this one chance\n",
      "Something's wrong, I can feel it (Six minutes,\n"
     ]
    }
   ],
   "source": [
    "for input_txt, target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model should be able to learn from anywhere\n",
    "#so let's suffle this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 7500\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((150, 150), (150, 150)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Model\n",
    "\n",
    "    Embedding\n",
    "    GRU\n",
    "    Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 756 #random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sparse_categorical_crossentropy in module tensorflow.python.keras.losses:\n",
      "\n",
      "sparse_categorical_crossentropy(y_true, y_pred, from_logits=False, axis=-1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true, y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GRU, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile('adam',loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size= vocab_size,\n",
    "                   embed_dim=embed_dim,\n",
    "                   rnn_neurons= rnn_neurons,\n",
    "                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (150, None, 64)           4096      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (150, None, 756)          1864296   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (150, None, 64)           48448     \n",
      "=================================================================\n",
      "Total params: 1,916,840\n",
      "Trainable params: 1,916,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predicstions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indixes = tf.random.categorical(example_batch_predicstions[0], num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indixes = tf.squeeze(sampled_indixes, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['M', 'G', 'R', 'h', '!', 'T', '-', '0', 'J', 'P', 'S', 't', 'x',\n",
       "       '7', 'g', 'Y', 'p', ' ', '4', '7', '.', '.', 'f', '\"', 'y', 'P',\n",
       "       'u', 'd', '.', 'i', '!', '!', 'w', '0', 'N', 'z', 'y', 'c', 't',\n",
       "       ',', 'l', '-', 'I', 'J', 'B', 'e', 'Y', 'T', 'O', 'i', 'e', 'v',\n",
       "       'i', 'g', 'J', 'o', '4', 'P', 'n', '4', 'K', 'p', 'N', 'o', 'A',\n",
       "       'j', 'b', 'c', 'f', 'Y', 'c', 'M', '2', 'o', 'S', '4', 'L', \"'\",\n",
       "       'c', '(', 'k', 'c', 'a', '(', 'S', 'd', ')', ',', 'k', 'y', 'Y',\n",
       "       \"'\", 'I', 'B', 'E', 'K', 'M', 's', 'f', 't', '4', 'Y', '7', 'z',\n",
       "       'o', '(', 'H', 'y', ',', '\"', 'O', ')', 'Y', 'P', 't', 'w', 't',\n",
       "       'U', 'R', 'Z', 'p', 'O', 'B', 'v', 'P', 'R', 'I', 'C', 'g', 'R',\n",
       "       'r', 'y', '4', 'o', 's', ' ', 'o', 'o', 'T', 'l', 'W', '2', 'p',\n",
       "       'I', ',', 'u', '0', 'g', 's', 'L'], dtype='<U1')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sampled_indixes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 9 steps\n",
      "Epoch 1/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 4.5333\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 3.9554\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 28s 3s/step - loss: 3.7459\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 27s 3s/step - loss: 3.3738\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 3.1436\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 27s 3s/step - loss: 3.0926\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 27s 3s/step - loss: 3.0376\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 2.9694\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 2.8802\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 27s 3s/step - loss: 2.7731\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 2.6682\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.5771\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 28s 3s/step - loss: 2.5054\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 29s 3s/step - loss: 2.4426\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 26s 3s/step - loss: 2.3943\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 28s 3s/step - loss: 2.3529\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.3190\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.2826\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.2480\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.2127\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.1776\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 2.1410\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 2.0987\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 2.0521\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 2.0088\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 1.9536\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.8956\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 1.8296\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 1.7597\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.6799\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.5912\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.4974\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.3904\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 24s 3s/step - loss: 1.2798\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.1563\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 1.0342\n",
      "Epoch 37/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.8991\n",
      "Epoch 38/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.7725\n",
      "Epoch 39/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.6519\n",
      "Epoch 40/40\n",
      "9/9 [==============================] - 25s 3s/step - loss: 0.5417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f980982d190>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('eminem_rap.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "\n",
    "model.load_weights('eminem_rap.h5')\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (1, None, 64)             4096      \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (1, None, 756)            1864296   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (1, None, 64)             48448     \n",
      "=================================================================\n",
      "Total params: 1,916,840\n",
      "Trainable params: 1,916,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
    "\n",
    "  num_generate = gen_size\n",
    "\n",
    "  input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  text_generated = []\n",
    "\n",
    "  temperature = temp\n",
    "\n",
    "  # Here batch size == 1\n",
    "  model.reset_states()\n",
    "\n",
    "  for i in range(num_generate):\n",
    "\n",
    "      # Generate Predictions\n",
    "      predictions = model(input_eval)\n",
    "\n",
    "      # Remove the batch shape dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # Use a cateogircal disitribution to select the next character\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # Pass the predicted charracter for the next input\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      # Transform back to character letter\n",
    "      text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "  return (start_seed + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am Beginning to Feel like a Rap God, Rake I La thow urenan to Sain's wrong to\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"I am Beginning to Feel like a\", gen_size=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
