{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv(\"iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         setosa\n",
       "1         setosa\n",
       "2         setosa\n",
       "3         setosa\n",
       "4         setosa\n",
       "         ...    \n",
       "145    virginica\n",
       "146    virginica\n",
       "147    virginica\n",
       "148    virginica\n",
       "149    virginica\n",
       "Name: species, Length: 150, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = iris['species']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=4, activation=\"relu\", input_shape=[4,]))\n",
    "\n",
    "model.add(Dense(units=3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5980 - accuracy: 0.7250 - val_loss: 0.6544 - val_accuracy: 0.6667\n",
      "Epoch 2/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5970 - accuracy: 0.7250 - val_loss: 0.6533 - val_accuracy: 0.6667\n",
      "Epoch 3/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5958 - accuracy: 0.7250 - val_loss: 0.6522 - val_accuracy: 0.6667\n",
      "Epoch 4/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.5948 - accuracy: 0.7250 - val_loss: 0.6510 - val_accuracy: 0.6667\n",
      "Epoch 5/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5937 - accuracy: 0.7250 - val_loss: 0.6498 - val_accuracy: 0.6667\n",
      "Epoch 6/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5926 - accuracy: 0.7250 - val_loss: 0.6488 - val_accuracy: 0.6667\n",
      "Epoch 7/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5915 - accuracy: 0.7250 - val_loss: 0.6477 - val_accuracy: 0.6667\n",
      "Epoch 8/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.5905 - accuracy: 0.7250 - val_loss: 0.6466 - val_accuracy: 0.6667\n",
      "Epoch 9/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.5893 - accuracy: 0.7250 - val_loss: 0.6454 - val_accuracy: 0.6667\n",
      "Epoch 10/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.5884 - accuracy: 0.7250 - val_loss: 0.6443 - val_accuracy: 0.6667\n",
      "Epoch 11/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.5872 - accuracy: 0.7250 - val_loss: 0.6430 - val_accuracy: 0.6667\n",
      "Epoch 12/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5862 - accuracy: 0.7250 - val_loss: 0.6418 - val_accuracy: 0.6667\n",
      "Epoch 13/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5852 - accuracy: 0.7250 - val_loss: 0.6406 - val_accuracy: 0.6667\n",
      "Epoch 14/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.5841 - accuracy: 0.7333 - val_loss: 0.6396 - val_accuracy: 0.6667\n",
      "Epoch 15/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5830 - accuracy: 0.7333 - val_loss: 0.6386 - val_accuracy: 0.6667\n",
      "Epoch 16/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5820 - accuracy: 0.7333 - val_loss: 0.6375 - val_accuracy: 0.6667\n",
      "Epoch 17/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.5810 - accuracy: 0.7333 - val_loss: 0.6364 - val_accuracy: 0.6667\n",
      "Epoch 18/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.5799 - accuracy: 0.7333 - val_loss: 0.6353 - val_accuracy: 0.6667\n",
      "Epoch 19/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5789 - accuracy: 0.7333 - val_loss: 0.6342 - val_accuracy: 0.6667\n",
      "Epoch 20/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.5779 - accuracy: 0.7333 - val_loss: 0.6329 - val_accuracy: 0.6667\n",
      "Epoch 21/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.5769 - accuracy: 0.7417 - val_loss: 0.6319 - val_accuracy: 0.6667\n",
      "Epoch 22/300\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 0.5759 - accuracy: 0.7417 - val_loss: 0.6308 - val_accuracy: 0.6667\n",
      "Epoch 23/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5748 - accuracy: 0.7417 - val_loss: 0.6297 - val_accuracy: 0.6667\n",
      "Epoch 24/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5739 - accuracy: 0.7417 - val_loss: 0.6284 - val_accuracy: 0.6667\n",
      "Epoch 25/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.5728 - accuracy: 0.7417 - val_loss: 0.6273 - val_accuracy: 0.6667\n",
      "Epoch 26/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.5718 - accuracy: 0.7417 - val_loss: 0.6263 - val_accuracy: 0.6667\n",
      "Epoch 27/300\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.5708 - accuracy: 0.7417 - val_loss: 0.6252 - val_accuracy: 0.6667\n",
      "Epoch 28/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.5698 - accuracy: 0.7417 - val_loss: 0.6241 - val_accuracy: 0.6667\n",
      "Epoch 29/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.5688 - accuracy: 0.7417 - val_loss: 0.6230 - val_accuracy: 0.6667\n",
      "Epoch 30/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5679 - accuracy: 0.7500 - val_loss: 0.6218 - val_accuracy: 0.6667\n",
      "Epoch 31/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.5668 - accuracy: 0.7500 - val_loss: 0.6210 - val_accuracy: 0.6667\n",
      "Epoch 32/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5659 - accuracy: 0.7500 - val_loss: 0.6200 - val_accuracy: 0.6667\n",
      "Epoch 33/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.5649 - accuracy: 0.7500 - val_loss: 0.6192 - val_accuracy: 0.6667\n",
      "Epoch 34/300\n",
      "120/120 [==============================] - 0s 153us/sample - loss: 0.5639 - accuracy: 0.7500 - val_loss: 0.6181 - val_accuracy: 0.6667\n",
      "Epoch 35/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5630 - accuracy: 0.7500 - val_loss: 0.6170 - val_accuracy: 0.6667\n",
      "Epoch 36/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5620 - accuracy: 0.7500 - val_loss: 0.6161 - val_accuracy: 0.6667\n",
      "Epoch 37/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5610 - accuracy: 0.7500 - val_loss: 0.6150 - val_accuracy: 0.6667\n",
      "Epoch 38/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.5601 - accuracy: 0.7500 - val_loss: 0.6139 - val_accuracy: 0.6667\n",
      "Epoch 39/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.5591 - accuracy: 0.7500 - val_loss: 0.6128 - val_accuracy: 0.6667\n",
      "Epoch 40/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.5581 - accuracy: 0.7500 - val_loss: 0.6117 - val_accuracy: 0.7000\n",
      "Epoch 41/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.5572 - accuracy: 0.7500 - val_loss: 0.6107 - val_accuracy: 0.7000\n",
      "Epoch 42/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5562 - accuracy: 0.7500 - val_loss: 0.6097 - val_accuracy: 0.7000\n",
      "Epoch 43/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5554 - accuracy: 0.7500 - val_loss: 0.6084 - val_accuracy: 0.7333\n",
      "Epoch 44/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.5543 - accuracy: 0.7500 - val_loss: 0.6074 - val_accuracy: 0.7333\n",
      "Epoch 45/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5535 - accuracy: 0.7500 - val_loss: 0.6064 - val_accuracy: 0.7333\n",
      "Epoch 46/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.5525 - accuracy: 0.7583 - val_loss: 0.6055 - val_accuracy: 0.7333\n",
      "Epoch 47/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.5516 - accuracy: 0.7583 - val_loss: 0.6044 - val_accuracy: 0.7333\n",
      "Epoch 48/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.5507 - accuracy: 0.7583 - val_loss: 0.6036 - val_accuracy: 0.7333\n",
      "Epoch 49/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5497 - accuracy: 0.7583 - val_loss: 0.6027 - val_accuracy: 0.7333\n",
      "Epoch 50/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.5488 - accuracy: 0.7583 - val_loss: 0.6016 - val_accuracy: 0.7333\n",
      "Epoch 51/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.5479 - accuracy: 0.7583 - val_loss: 0.6006 - val_accuracy: 0.7333\n",
      "Epoch 52/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.5470 - accuracy: 0.7583 - val_loss: 0.5993 - val_accuracy: 0.7333\n",
      "Epoch 53/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.5460 - accuracy: 0.7750 - val_loss: 0.5983 - val_accuracy: 0.7333\n",
      "Epoch 54/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.5451 - accuracy: 0.7750 - val_loss: 0.5972 - val_accuracy: 0.7333\n",
      "Epoch 55/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.5442 - accuracy: 0.7750 - val_loss: 0.5962 - val_accuracy: 0.7333\n",
      "Epoch 56/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 120us/sample - loss: 0.5433 - accuracy: 0.7833 - val_loss: 0.5952 - val_accuracy: 0.7333\n",
      "Epoch 57/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5424 - accuracy: 0.7833 - val_loss: 0.5944 - val_accuracy: 0.7333\n",
      "Epoch 58/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5415 - accuracy: 0.7833 - val_loss: 0.5934 - val_accuracy: 0.7333\n",
      "Epoch 59/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5406 - accuracy: 0.7833 - val_loss: 0.5925 - val_accuracy: 0.7333\n",
      "Epoch 60/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.5398 - accuracy: 0.7833 - val_loss: 0.5914 - val_accuracy: 0.7333\n",
      "Epoch 61/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.5388 - accuracy: 0.7833 - val_loss: 0.5905 - val_accuracy: 0.7333\n",
      "Epoch 62/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.5379 - accuracy: 0.7833 - val_loss: 0.5896 - val_accuracy: 0.7333\n",
      "Epoch 63/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5370 - accuracy: 0.7833 - val_loss: 0.5887 - val_accuracy: 0.7333\n",
      "Epoch 64/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.5362 - accuracy: 0.7833 - val_loss: 0.5878 - val_accuracy: 0.7333\n",
      "Epoch 65/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.5352 - accuracy: 0.7833 - val_loss: 0.5868 - val_accuracy: 0.7333\n",
      "Epoch 66/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.5344 - accuracy: 0.7833 - val_loss: 0.5858 - val_accuracy: 0.7333\n",
      "Epoch 67/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5335 - accuracy: 0.7833 - val_loss: 0.5847 - val_accuracy: 0.7667\n",
      "Epoch 68/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5326 - accuracy: 0.7833 - val_loss: 0.5836 - val_accuracy: 0.7667\n",
      "Epoch 69/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.5318 - accuracy: 0.7833 - val_loss: 0.5826 - val_accuracy: 0.7667\n",
      "Epoch 70/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5309 - accuracy: 0.7833 - val_loss: 0.5816 - val_accuracy: 0.7667\n",
      "Epoch 71/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5300 - accuracy: 0.7833 - val_loss: 0.5806 - val_accuracy: 0.7667\n",
      "Epoch 72/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5292 - accuracy: 0.7833 - val_loss: 0.5795 - val_accuracy: 0.7667\n",
      "Epoch 73/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.5283 - accuracy: 0.7833 - val_loss: 0.5786 - val_accuracy: 0.7667\n",
      "Epoch 74/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5274 - accuracy: 0.7833 - val_loss: 0.5778 - val_accuracy: 0.7667\n",
      "Epoch 75/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.5266 - accuracy: 0.7833 - val_loss: 0.5769 - val_accuracy: 0.7667\n",
      "Epoch 76/300\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.5256 - accuracy: 0.7833 - val_loss: 0.5760 - val_accuracy: 0.7667\n",
      "Epoch 77/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5249 - accuracy: 0.7833 - val_loss: 0.5751 - val_accuracy: 0.7667\n",
      "Epoch 78/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.5240 - accuracy: 0.7833 - val_loss: 0.5743 - val_accuracy: 0.7667\n",
      "Epoch 79/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5231 - accuracy: 0.7833 - val_loss: 0.5735 - val_accuracy: 0.7667\n",
      "Epoch 80/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.5225 - accuracy: 0.7833 - val_loss: 0.5729 - val_accuracy: 0.7667\n",
      "Epoch 81/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.5215 - accuracy: 0.7833 - val_loss: 0.5718 - val_accuracy: 0.7667\n",
      "Epoch 82/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.5206 - accuracy: 0.7917 - val_loss: 0.5708 - val_accuracy: 0.7667\n",
      "Epoch 83/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5197 - accuracy: 0.8000 - val_loss: 0.5700 - val_accuracy: 0.7667\n",
      "Epoch 84/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5189 - accuracy: 0.8000 - val_loss: 0.5690 - val_accuracy: 0.7667\n",
      "Epoch 85/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.5180 - accuracy: 0.8000 - val_loss: 0.5682 - val_accuracy: 0.7667\n",
      "Epoch 86/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.5173 - accuracy: 0.8000 - val_loss: 0.5674 - val_accuracy: 0.7667\n",
      "Epoch 87/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.5163 - accuracy: 0.8083 - val_loss: 0.5663 - val_accuracy: 0.8000\n",
      "Epoch 88/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.5156 - accuracy: 0.8083 - val_loss: 0.5651 - val_accuracy: 0.8000\n",
      "Epoch 89/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.5147 - accuracy: 0.8083 - val_loss: 0.5641 - val_accuracy: 0.8000\n",
      "Epoch 90/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5138 - accuracy: 0.8083 - val_loss: 0.5631 - val_accuracy: 0.8000\n",
      "Epoch 91/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.5129 - accuracy: 0.8083 - val_loss: 0.5621 - val_accuracy: 0.8000\n",
      "Epoch 92/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5122 - accuracy: 0.8083 - val_loss: 0.5611 - val_accuracy: 0.8000\n",
      "Epoch 93/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.5113 - accuracy: 0.8083 - val_loss: 0.5603 - val_accuracy: 0.8000\n",
      "Epoch 94/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.5105 - accuracy: 0.8083 - val_loss: 0.5593 - val_accuracy: 0.8000\n",
      "Epoch 95/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.5097 - accuracy: 0.8083 - val_loss: 0.5582 - val_accuracy: 0.8333\n",
      "Epoch 96/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.5088 - accuracy: 0.8083 - val_loss: 0.5574 - val_accuracy: 0.8333\n",
      "Epoch 97/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.5081 - accuracy: 0.8083 - val_loss: 0.5562 - val_accuracy: 0.8333\n",
      "Epoch 98/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.5072 - accuracy: 0.8083 - val_loss: 0.5555 - val_accuracy: 0.8333\n",
      "Epoch 99/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.5063 - accuracy: 0.8083 - val_loss: 0.5546 - val_accuracy: 0.8333\n",
      "Epoch 100/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.5056 - accuracy: 0.8083 - val_loss: 0.5536 - val_accuracy: 0.8333\n",
      "Epoch 101/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.5047 - accuracy: 0.8083 - val_loss: 0.5527 - val_accuracy: 0.8333\n",
      "Epoch 102/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5038 - accuracy: 0.8083 - val_loss: 0.5520 - val_accuracy: 0.8333\n",
      "Epoch 103/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.5030 - accuracy: 0.8083 - val_loss: 0.5513 - val_accuracy: 0.8333\n",
      "Epoch 104/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.5022 - accuracy: 0.8083 - val_loss: 0.5504 - val_accuracy: 0.8333\n",
      "Epoch 105/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.5014 - accuracy: 0.8083 - val_loss: 0.5494 - val_accuracy: 0.8333\n",
      "Epoch 106/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.5006 - accuracy: 0.8083 - val_loss: 0.5486 - val_accuracy: 0.8333\n",
      "Epoch 107/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.4998 - accuracy: 0.8167 - val_loss: 0.5478 - val_accuracy: 0.8333\n",
      "Epoch 108/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4991 - accuracy: 0.8167 - val_loss: 0.5467 - val_accuracy: 0.8333\n",
      "Epoch 109/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.4981 - accuracy: 0.8167 - val_loss: 0.5459 - val_accuracy: 0.8333\n",
      "Epoch 110/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.4974 - accuracy: 0.8167 - val_loss: 0.5452 - val_accuracy: 0.8333\n",
      "Epoch 111/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 131us/sample - loss: 0.4966 - accuracy: 0.8167 - val_loss: 0.5441 - val_accuracy: 0.8333\n",
      "Epoch 112/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4957 - accuracy: 0.8167 - val_loss: 0.5432 - val_accuracy: 0.8333\n",
      "Epoch 113/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.4950 - accuracy: 0.8167 - val_loss: 0.5424 - val_accuracy: 0.8333\n",
      "Epoch 114/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.4941 - accuracy: 0.8167 - val_loss: 0.5415 - val_accuracy: 0.8333\n",
      "Epoch 115/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.4932 - accuracy: 0.8167 - val_loss: 0.5405 - val_accuracy: 0.8333\n",
      "Epoch 116/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.4926 - accuracy: 0.8167 - val_loss: 0.5394 - val_accuracy: 0.8333\n",
      "Epoch 117/300\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 0.4917 - accuracy: 0.8167 - val_loss: 0.5384 - val_accuracy: 0.8333\n",
      "Epoch 118/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4909 - accuracy: 0.8167 - val_loss: 0.5378 - val_accuracy: 0.8333\n",
      "Epoch 119/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.4901 - accuracy: 0.8167 - val_loss: 0.5369 - val_accuracy: 0.8333\n",
      "Epoch 120/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4893 - accuracy: 0.8167 - val_loss: 0.5360 - val_accuracy: 0.8333\n",
      "Epoch 121/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4886 - accuracy: 0.8250 - val_loss: 0.5349 - val_accuracy: 0.8333\n",
      "Epoch 122/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.4877 - accuracy: 0.8250 - val_loss: 0.5342 - val_accuracy: 0.8333\n",
      "Epoch 123/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.4869 - accuracy: 0.8250 - val_loss: 0.5334 - val_accuracy: 0.8333\n",
      "Epoch 124/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4861 - accuracy: 0.8250 - val_loss: 0.5324 - val_accuracy: 0.8333\n",
      "Epoch 125/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4853 - accuracy: 0.8250 - val_loss: 0.5314 - val_accuracy: 0.8333\n",
      "Epoch 126/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.4845 - accuracy: 0.8250 - val_loss: 0.5305 - val_accuracy: 0.8333\n",
      "Epoch 127/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4837 - accuracy: 0.8250 - val_loss: 0.5297 - val_accuracy: 0.8333\n",
      "Epoch 128/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.4829 - accuracy: 0.8250 - val_loss: 0.5289 - val_accuracy: 0.8333\n",
      "Epoch 129/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.4821 - accuracy: 0.8250 - val_loss: 0.5280 - val_accuracy: 0.8333\n",
      "Epoch 130/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4813 - accuracy: 0.8250 - val_loss: 0.5271 - val_accuracy: 0.8333\n",
      "Epoch 131/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4805 - accuracy: 0.8250 - val_loss: 0.5260 - val_accuracy: 0.8333\n",
      "Epoch 132/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4797 - accuracy: 0.8250 - val_loss: 0.5250 - val_accuracy: 0.8333\n",
      "Epoch 133/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.4789 - accuracy: 0.8250 - val_loss: 0.5240 - val_accuracy: 0.8333\n",
      "Epoch 134/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.4782 - accuracy: 0.8250 - val_loss: 0.5233 - val_accuracy: 0.8333\n",
      "Epoch 135/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4773 - accuracy: 0.8250 - val_loss: 0.5223 - val_accuracy: 0.8333\n",
      "Epoch 136/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4766 - accuracy: 0.8250 - val_loss: 0.5213 - val_accuracy: 0.8333\n",
      "Epoch 137/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.4757 - accuracy: 0.8167 - val_loss: 0.5206 - val_accuracy: 0.8333\n",
      "Epoch 138/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.4750 - accuracy: 0.8167 - val_loss: 0.5197 - val_accuracy: 0.8333\n",
      "Epoch 139/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4742 - accuracy: 0.8250 - val_loss: 0.5190 - val_accuracy: 0.8333\n",
      "Epoch 140/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4734 - accuracy: 0.8167 - val_loss: 0.5182 - val_accuracy: 0.8333\n",
      "Epoch 141/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.4726 - accuracy: 0.8250 - val_loss: 0.5172 - val_accuracy: 0.8333\n",
      "Epoch 142/300\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 0.4718 - accuracy: 0.8250 - val_loss: 0.5163 - val_accuracy: 0.8333\n",
      "Epoch 143/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4712 - accuracy: 0.8250 - val_loss: 0.5152 - val_accuracy: 0.8667\n",
      "Epoch 144/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4702 - accuracy: 0.8250 - val_loss: 0.5146 - val_accuracy: 0.8667\n",
      "Epoch 145/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4695 - accuracy: 0.8250 - val_loss: 0.5139 - val_accuracy: 0.8667\n",
      "Epoch 146/300\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.4687 - accuracy: 0.8250 - val_loss: 0.5131 - val_accuracy: 0.8667\n",
      "Epoch 147/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.4680 - accuracy: 0.8250 - val_loss: 0.5121 - val_accuracy: 0.8667\n",
      "Epoch 148/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4670 - accuracy: 0.8333 - val_loss: 0.5113 - val_accuracy: 0.8667\n",
      "Epoch 149/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.4663 - accuracy: 0.8333 - val_loss: 0.5106 - val_accuracy: 0.8667\n",
      "Epoch 150/300\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.4655 - accuracy: 0.8333 - val_loss: 0.5096 - val_accuracy: 0.8667\n",
      "Epoch 151/300\n",
      "120/120 [==============================] - 0s 134us/sample - loss: 0.4647 - accuracy: 0.8333 - val_loss: 0.5088 - val_accuracy: 0.8667\n",
      "Epoch 152/300\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.4639 - accuracy: 0.8333 - val_loss: 0.5079 - val_accuracy: 0.8667\n",
      "Epoch 153/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.4633 - accuracy: 0.8333 - val_loss: 0.5072 - val_accuracy: 0.8667\n",
      "Epoch 154/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4624 - accuracy: 0.8333 - val_loss: 0.5062 - val_accuracy: 0.8667\n",
      "Epoch 155/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.4616 - accuracy: 0.8417 - val_loss: 0.5052 - val_accuracy: 0.8667\n",
      "Epoch 156/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.4609 - accuracy: 0.8417 - val_loss: 0.5045 - val_accuracy: 0.8667\n",
      "Epoch 157/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.4600 - accuracy: 0.8417 - val_loss: 0.5035 - val_accuracy: 0.8667\n",
      "Epoch 158/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4593 - accuracy: 0.8417 - val_loss: 0.5026 - val_accuracy: 0.8667\n",
      "Epoch 159/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.4585 - accuracy: 0.8417 - val_loss: 0.5019 - val_accuracy: 0.8667\n",
      "Epoch 160/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.4577 - accuracy: 0.8417 - val_loss: 0.5011 - val_accuracy: 0.8667\n",
      "Epoch 161/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.4569 - accuracy: 0.8417 - val_loss: 0.5002 - val_accuracy: 0.8667\n",
      "Epoch 162/300\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.4562 - accuracy: 0.8417 - val_loss: 0.4995 - val_accuracy: 0.8667\n",
      "Epoch 163/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.4554 - accuracy: 0.8417 - val_loss: 0.4986 - val_accuracy: 0.8667\n",
      "Epoch 164/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.4546 - accuracy: 0.8417 - val_loss: 0.4976 - val_accuracy: 0.9000\n",
      "Epoch 165/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4538 - accuracy: 0.8417 - val_loss: 0.4967 - val_accuracy: 0.9000\n",
      "Epoch 166/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4530 - accuracy: 0.8417 - val_loss: 0.4958 - val_accuracy: 0.9000\n",
      "Epoch 167/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.4523 - accuracy: 0.8417 - val_loss: 0.4948 - val_accuracy: 0.9000\n",
      "Epoch 168/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4515 - accuracy: 0.8500 - val_loss: 0.4941 - val_accuracy: 0.9000\n",
      "Epoch 169/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.4507 - accuracy: 0.8500 - val_loss: 0.4931 - val_accuracy: 0.9000\n",
      "Epoch 170/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4500 - accuracy: 0.8500 - val_loss: 0.4922 - val_accuracy: 0.9000\n",
      "Epoch 171/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4491 - accuracy: 0.8500 - val_loss: 0.4914 - val_accuracy: 0.9000\n",
      "Epoch 172/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.4485 - accuracy: 0.8500 - val_loss: 0.4905 - val_accuracy: 0.9000\n",
      "Epoch 173/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.4477 - accuracy: 0.8500 - val_loss: 0.4899 - val_accuracy: 0.9000\n",
      "Epoch 174/300\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.4468 - accuracy: 0.8500 - val_loss: 0.4891 - val_accuracy: 0.9000\n",
      "Epoch 175/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.4460 - accuracy: 0.8500 - val_loss: 0.4881 - val_accuracy: 0.9000\n",
      "Epoch 176/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4453 - accuracy: 0.8583 - val_loss: 0.4870 - val_accuracy: 0.9000\n",
      "Epoch 177/300\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.4445 - accuracy: 0.8583 - val_loss: 0.4861 - val_accuracy: 0.9000\n",
      "Epoch 178/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.4438 - accuracy: 0.8583 - val_loss: 0.4851 - val_accuracy: 0.9000\n",
      "Epoch 179/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.4429 - accuracy: 0.8583 - val_loss: 0.4843 - val_accuracy: 0.9000\n",
      "Epoch 180/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.4421 - accuracy: 0.8583 - val_loss: 0.4835 - val_accuracy: 0.9000\n",
      "Epoch 181/300\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 0.4414 - accuracy: 0.8583 - val_loss: 0.4826 - val_accuracy: 0.9000\n",
      "Epoch 182/300\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.4407 - accuracy: 0.8583 - val_loss: 0.4819 - val_accuracy: 0.9000\n",
      "Epoch 183/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.4398 - accuracy: 0.8583 - val_loss: 0.4809 - val_accuracy: 0.9000\n",
      "Epoch 184/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4392 - accuracy: 0.8583 - val_loss: 0.4799 - val_accuracy: 0.9000\n",
      "Epoch 185/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.4383 - accuracy: 0.8583 - val_loss: 0.4790 - val_accuracy: 0.9000\n",
      "Epoch 186/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.4376 - accuracy: 0.8583 - val_loss: 0.4782 - val_accuracy: 0.9000\n",
      "Epoch 187/300\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.4369 - accuracy: 0.8583 - val_loss: 0.4771 - val_accuracy: 0.9000\n",
      "Epoch 188/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.4361 - accuracy: 0.8583 - val_loss: 0.4765 - val_accuracy: 0.9000\n",
      "Epoch 189/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.4353 - accuracy: 0.8583 - val_loss: 0.4757 - val_accuracy: 0.9000\n",
      "Epoch 190/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.4345 - accuracy: 0.8583 - val_loss: 0.4748 - val_accuracy: 0.9000\n",
      "Epoch 191/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4339 - accuracy: 0.8583 - val_loss: 0.4739 - val_accuracy: 0.9000\n",
      "Epoch 192/300\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.4330 - accuracy: 0.8583 - val_loss: 0.4730 - val_accuracy: 0.9000\n",
      "Epoch 193/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.4323 - accuracy: 0.8583 - val_loss: 0.4721 - val_accuracy: 0.9000\n",
      "Epoch 194/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.4315 - accuracy: 0.8583 - val_loss: 0.4714 - val_accuracy: 0.9000\n",
      "Epoch 195/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.4307 - accuracy: 0.8583 - val_loss: 0.4707 - val_accuracy: 0.9000\n",
      "Epoch 196/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.4301 - accuracy: 0.8583 - val_loss: 0.4699 - val_accuracy: 0.9000\n",
      "Epoch 197/300\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.4292 - accuracy: 0.8583 - val_loss: 0.4692 - val_accuracy: 0.9000\n",
      "Epoch 198/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.4285 - accuracy: 0.8583 - val_loss: 0.4685 - val_accuracy: 0.9000\n",
      "Epoch 199/300\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.4278 - accuracy: 0.8583 - val_loss: 0.4677 - val_accuracy: 0.9000\n",
      "Epoch 200/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4270 - accuracy: 0.8583 - val_loss: 0.4669 - val_accuracy: 0.9000\n",
      "Epoch 201/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4264 - accuracy: 0.8583 - val_loss: 0.4664 - val_accuracy: 0.9000\n",
      "Epoch 202/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.4255 - accuracy: 0.8583 - val_loss: 0.4656 - val_accuracy: 0.9000\n",
      "Epoch 203/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.4248 - accuracy: 0.8583 - val_loss: 0.4647 - val_accuracy: 0.9000\n",
      "Epoch 204/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.4241 - accuracy: 0.8583 - val_loss: 0.4638 - val_accuracy: 0.9000\n",
      "Epoch 205/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.4233 - accuracy: 0.8583 - val_loss: 0.4629 - val_accuracy: 0.9000\n",
      "Epoch 206/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4226 - accuracy: 0.8667 - val_loss: 0.4620 - val_accuracy: 0.9000\n",
      "Epoch 207/300\n",
      "120/120 [==============================] - 0s 177us/sample - loss: 0.4219 - accuracy: 0.8667 - val_loss: 0.4611 - val_accuracy: 0.9000\n",
      "Epoch 208/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.4212 - accuracy: 0.8667 - val_loss: 0.4601 - val_accuracy: 0.9000\n",
      "Epoch 209/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4205 - accuracy: 0.8667 - val_loss: 0.4593 - val_accuracy: 0.9000\n",
      "Epoch 210/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.4198 - accuracy: 0.8667 - val_loss: 0.4584 - val_accuracy: 0.9000\n",
      "Epoch 211/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.4190 - accuracy: 0.8667 - val_loss: 0.4578 - val_accuracy: 0.9000\n",
      "Epoch 212/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4183 - accuracy: 0.8667 - val_loss: 0.4572 - val_accuracy: 0.9000\n",
      "Epoch 213/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4175 - accuracy: 0.8667 - val_loss: 0.4564 - val_accuracy: 0.9000\n",
      "Epoch 214/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4168 - accuracy: 0.8667 - val_loss: 0.4557 - val_accuracy: 0.9000\n",
      "Epoch 215/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.4162 - accuracy: 0.8667 - val_loss: 0.4548 - val_accuracy: 0.9000\n",
      "Epoch 216/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.4153 - accuracy: 0.8667 - val_loss: 0.4540 - val_accuracy: 0.9000\n",
      "Epoch 217/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4147 - accuracy: 0.8667 - val_loss: 0.4534 - val_accuracy: 0.9000\n",
      "Epoch 218/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.4141 - accuracy: 0.8750 - val_loss: 0.4524 - val_accuracy: 0.9000\n",
      "Epoch 219/300\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.4132 - accuracy: 0.8917 - val_loss: 0.4516 - val_accuracy: 0.9000\n",
      "Epoch 220/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.4125 - accuracy: 0.8917 - val_loss: 0.4508 - val_accuracy: 0.9000\n",
      "Epoch 221/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 122us/sample - loss: 0.4118 - accuracy: 0.8833 - val_loss: 0.4502 - val_accuracy: 0.9000\n",
      "Epoch 222/300\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.4111 - accuracy: 0.8833 - val_loss: 0.4496 - val_accuracy: 0.9000\n",
      "Epoch 223/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.4103 - accuracy: 0.8917 - val_loss: 0.4486 - val_accuracy: 0.9000\n",
      "Epoch 224/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.4095 - accuracy: 0.8917 - val_loss: 0.4479 - val_accuracy: 0.9000\n",
      "Epoch 225/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.4088 - accuracy: 0.8917 - val_loss: 0.4472 - val_accuracy: 0.9000\n",
      "Epoch 226/300\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.4081 - accuracy: 0.8917 - val_loss: 0.4463 - val_accuracy: 0.9000\n",
      "Epoch 227/300\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.4074 - accuracy: 0.8917 - val_loss: 0.4453 - val_accuracy: 0.9333\n",
      "Epoch 228/300\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.4071 - accuracy: 0.8917 - val_loss: 0.4442 - val_accuracy: 0.9333\n",
      "Epoch 229/300\n",
      "120/120 [==============================] - 0s 173us/sample - loss: 0.4059 - accuracy: 0.9000 - val_loss: 0.4435 - val_accuracy: 0.9333\n",
      "Epoch 230/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.4052 - accuracy: 0.8917 - val_loss: 0.4429 - val_accuracy: 0.9333\n",
      "Epoch 231/300\n",
      "120/120 [==============================] - 0s 159us/sample - loss: 0.4045 - accuracy: 0.8917 - val_loss: 0.4422 - val_accuracy: 0.9333\n",
      "Epoch 232/300\n",
      "120/120 [==============================] - 0s 164us/sample - loss: 0.4039 - accuracy: 0.8917 - val_loss: 0.4416 - val_accuracy: 0.9000\n",
      "Epoch 233/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.4031 - accuracy: 0.8917 - val_loss: 0.4408 - val_accuracy: 0.9333\n",
      "Epoch 234/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.4024 - accuracy: 0.8917 - val_loss: 0.4400 - val_accuracy: 0.9333\n",
      "Epoch 235/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.4018 - accuracy: 0.9000 - val_loss: 0.4389 - val_accuracy: 0.9333\n",
      "Epoch 236/300\n",
      "120/120 [==============================] - 0s 168us/sample - loss: 0.4009 - accuracy: 0.9000 - val_loss: 0.4381 - val_accuracy: 0.9333\n",
      "Epoch 237/300\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.4003 - accuracy: 0.9000 - val_loss: 0.4372 - val_accuracy: 0.9333\n",
      "Epoch 238/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.3995 - accuracy: 0.9000 - val_loss: 0.4364 - val_accuracy: 0.9333\n",
      "Epoch 239/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.3988 - accuracy: 0.9000 - val_loss: 0.4357 - val_accuracy: 0.9333\n",
      "Epoch 240/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.3981 - accuracy: 0.9000 - val_loss: 0.4351 - val_accuracy: 0.9333\n",
      "Epoch 241/300\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.3974 - accuracy: 0.9000 - val_loss: 0.4344 - val_accuracy: 0.9333\n",
      "Epoch 242/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.3967 - accuracy: 0.9000 - val_loss: 0.4337 - val_accuracy: 0.9333\n",
      "Epoch 243/300\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.3960 - accuracy: 0.9000 - val_loss: 0.4330 - val_accuracy: 0.9333\n",
      "Epoch 244/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.3953 - accuracy: 0.9000 - val_loss: 0.4322 - val_accuracy: 0.9333\n",
      "Epoch 245/300\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.3946 - accuracy: 0.9000 - val_loss: 0.4312 - val_accuracy: 0.9667\n",
      "Epoch 246/300\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.3938 - accuracy: 0.9000 - val_loss: 0.4303 - val_accuracy: 0.9667\n",
      "Epoch 247/300\n",
      "120/120 [==============================] - 0s 172us/sample - loss: 0.3932 - accuracy: 0.9000 - val_loss: 0.4295 - val_accuracy: 0.9667\n",
      "Epoch 248/300\n",
      "120/120 [==============================] - 0s 138us/sample - loss: 0.3926 - accuracy: 0.9000 - val_loss: 0.4285 - val_accuracy: 0.9667\n",
      "Epoch 249/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.3917 - accuracy: 0.9000 - val_loss: 0.4276 - val_accuracy: 0.9667\n",
      "Epoch 250/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.3911 - accuracy: 0.9000 - val_loss: 0.4268 - val_accuracy: 0.9667\n",
      "Epoch 251/300\n",
      "120/120 [==============================] - 0s 156us/sample - loss: 0.3903 - accuracy: 0.9000 - val_loss: 0.4262 - val_accuracy: 0.9667\n",
      "Epoch 252/300\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.3896 - accuracy: 0.9000 - val_loss: 0.4255 - val_accuracy: 0.9667\n",
      "Epoch 253/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.3889 - accuracy: 0.9000 - val_loss: 0.4247 - val_accuracy: 0.9667\n",
      "Epoch 254/300\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 0.3882 - accuracy: 0.9000 - val_loss: 0.4239 - val_accuracy: 0.9667\n",
      "Epoch 255/300\n",
      "120/120 [==============================] - 0s 162us/sample - loss: 0.3875 - accuracy: 0.9000 - val_loss: 0.4230 - val_accuracy: 0.9667\n",
      "Epoch 256/300\n",
      "120/120 [==============================] - 0s 145us/sample - loss: 0.3868 - accuracy: 0.9000 - val_loss: 0.4222 - val_accuracy: 0.9667\n",
      "Epoch 257/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.3862 - accuracy: 0.9000 - val_loss: 0.4216 - val_accuracy: 0.9667\n",
      "Epoch 258/300\n",
      "120/120 [==============================] - 0s 154us/sample - loss: 0.3855 - accuracy: 0.9000 - val_loss: 0.4207 - val_accuracy: 0.9667\n",
      "Epoch 259/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.3847 - accuracy: 0.9000 - val_loss: 0.4200 - val_accuracy: 0.9667\n",
      "Epoch 260/300\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.3840 - accuracy: 0.9000 - val_loss: 0.4193 - val_accuracy: 0.9667\n",
      "Epoch 261/300\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.3833 - accuracy: 0.9000 - val_loss: 0.4185 - val_accuracy: 0.9667\n",
      "Epoch 262/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.3826 - accuracy: 0.9000 - val_loss: 0.4178 - val_accuracy: 0.9667\n",
      "Epoch 263/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.3819 - accuracy: 0.9000 - val_loss: 0.4170 - val_accuracy: 0.9667\n",
      "Epoch 264/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.3813 - accuracy: 0.9000 - val_loss: 0.4163 - val_accuracy: 0.9667\n",
      "Epoch 265/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.3806 - accuracy: 0.9000 - val_loss: 0.4153 - val_accuracy: 0.9667\n",
      "Epoch 266/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.3799 - accuracy: 0.9167 - val_loss: 0.4145 - val_accuracy: 0.9667\n",
      "Epoch 267/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.3792 - accuracy: 0.9167 - val_loss: 0.4139 - val_accuracy: 0.9667\n",
      "Epoch 268/300\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.3785 - accuracy: 0.9083 - val_loss: 0.4132 - val_accuracy: 0.9667\n",
      "Epoch 269/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.3779 - accuracy: 0.9167 - val_loss: 0.4125 - val_accuracy: 0.9667\n",
      "Epoch 270/300\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.3772 - accuracy: 0.9167 - val_loss: 0.4117 - val_accuracy: 0.9667\n",
      "Epoch 271/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.3765 - accuracy: 0.9167 - val_loss: 0.4111 - val_accuracy: 0.9667\n",
      "Epoch 272/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.3759 - accuracy: 0.9167 - val_loss: 0.4104 - val_accuracy: 0.9667\n",
      "Epoch 273/300\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.3752 - accuracy: 0.9167 - val_loss: 0.4098 - val_accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "120/120 [==============================] - 0s 151us/sample - loss: 0.3745 - accuracy: 0.9083 - val_loss: 0.4090 - val_accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "120/120 [==============================] - 0s 190us/sample - loss: 0.3740 - accuracy: 0.9167 - val_loss: 0.4081 - val_accuracy: 0.9667\n",
      "Epoch 276/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 150us/sample - loss: 0.3732 - accuracy: 0.9167 - val_loss: 0.4075 - val_accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.3726 - accuracy: 0.9167 - val_loss: 0.4069 - val_accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.3719 - accuracy: 0.9167 - val_loss: 0.4061 - val_accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.3712 - accuracy: 0.9167 - val_loss: 0.4053 - val_accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.3707 - accuracy: 0.9167 - val_loss: 0.4047 - val_accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "120/120 [==============================] - 0s 136us/sample - loss: 0.3700 - accuracy: 0.9167 - val_loss: 0.4038 - val_accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.3694 - accuracy: 0.9167 - val_loss: 0.4031 - val_accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 0.3686 - accuracy: 0.9167 - val_loss: 0.4021 - val_accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.3679 - accuracy: 0.9167 - val_loss: 0.4013 - val_accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.3673 - accuracy: 0.9167 - val_loss: 0.4004 - val_accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.3666 - accuracy: 0.9167 - val_loss: 0.3998 - val_accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.3659 - accuracy: 0.9167 - val_loss: 0.3991 - val_accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.3653 - accuracy: 0.9167 - val_loss: 0.3984 - val_accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.3647 - accuracy: 0.9167 - val_loss: 0.3976 - val_accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.3640 - accuracy: 0.9167 - val_loss: 0.3970 - val_accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.3636 - accuracy: 0.9167 - val_loss: 0.3961 - val_accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.3627 - accuracy: 0.9167 - val_loss: 0.3954 - val_accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.3620 - accuracy: 0.9167 - val_loss: 0.3947 - val_accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.3614 - accuracy: 0.9167 - val_loss: 0.3940 - val_accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.3607 - accuracy: 0.9167 - val_loss: 0.3933 - val_accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.3601 - accuracy: 0.9167 - val_loss: 0.3926 - val_accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.3594 - accuracy: 0.9167 - val_loss: 0.3918 - val_accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.3588 - accuracy: 0.9167 - val_loss: 0.3911 - val_accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.3582 - accuracy: 0.9167 - val_loss: 0.3902 - val_accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.3575 - accuracy: 0.9167 - val_loss: 0.3895 - val_accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b685ebd10>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=scaled_X_train, y =y_train, epochs=300,\n",
    "         validation_data=(scaled_X_test, y_test),\n",
    "         callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.598046</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.654379</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.596969</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.653297</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.595849</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.652155</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.594763</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.650977</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.593652</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.649849</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>0.360064</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.392597</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>296</td>\n",
       "      <td>0.359419</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.391790</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.391130</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>0.358187</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.390229</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>299</td>\n",
       "      <td>0.357455</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.389474</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    0.598046  0.725000  0.654379      0.666667\n",
       "1    0.596969  0.725000  0.653297      0.666667\n",
       "2    0.595849  0.725000  0.652155      0.666667\n",
       "3    0.594763  0.725000  0.650977      0.666667\n",
       "4    0.593652  0.725000  0.649849      0.666667\n",
       "..        ...       ...       ...           ...\n",
       "295  0.360064  0.916667  0.392597      0.966667\n",
       "296  0.359419  0.916667  0.391790      0.966667\n",
       "297  0.358833  0.916667  0.391130      0.966667\n",
       "298  0.358187  0.916667  0.390229      0.966667\n",
       "299  0.357455  0.916667  0.389474      0.966667\n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b705a5d90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deVxV1fr48c9iFpwHBJlRTFNyAGfFKdNssNLKLFPLTC3r11y3W5m3vnXrZjaYNlqWpc3X6uY8z4DinAooMigiiIIyn/X7Yx/vJRM9KrA5m+f9evGCs8/e5zzL4+thsfZaz1Jaa4QQQliXi9kBCCGEqFqS6IUQwuIk0QshhMVJohdCCIuTRC+EEBbnZnYA52ratKkODQ01OwwhhHAq8fHxx7XWzc73XI1L9KGhocTFxZkdhhBCOBWlVEpFz8nQjRBCWJwkeiGEsDhJ9EIIYXE1boxeCFE7lZSUkJaWRmFhodmh1GheXl4EBgbi7u7u8DWS6IUQNUJaWhr16tUjNDQUpZTZ4dRIWmuys7NJS0sjLCzM4etk6EYIUSMUFhbSpEkTSfIXoJSiSZMml/xXjyR6IUSNIUn+4i7n36jmJfqT6VCQa3YUQghhGQ4leqXUEKXUPqVUolLq2QrOuUMptUcptVsp9XW542VKqQT718KLvtnpLPigBxxY5nAjhBCiMtStW9fsEKrERW/GKqVcgZnAICANiFVKLdRa7yl3TgTwHNBLa31CKeVb7iUKtNYdHY6oWWvwqgfzhkPne+G6V8GrvsOXCyGE+DNHevRdgUStdbLWuhiYDww755wHgJla6xMAWutjlx2RuzdMWA29/h9s+wpm9YSDay775YQQ4lJprXnqqado3749kZGRLFiwAIAjR44QExNDx44dad++PWvXrqWsrIyxY8f+99y3337b5Oj/ypHplQFAarnHaUC3c85pDaCUWg+4AlO11ovsz3kppeKAUuB1rfXP576BUmoCMAEgODgY3L1g0MvQ5gb4aSJ8cRN0mwgDXwIP70tqoBDC+bz8y272ZJyq1Ne8ukV9XrqpnUPn/vjjjyQkJLB9+3aOHz9Oly5diImJ4euvv2bw4ME8//zzlJWVcebMGRISEkhPT2fXrl0A5ObWvHuMjvToz3eL99yNZt2ACKAfcBfwiVKqof25YK11NDAKmKGUavmXF9P6I611tNY6ulmzcsXXgrrCxLXQdQJsng0fxkCaFDwTQlStdevWcdddd+Hq6krz5s3p27cvsbGxdOnShTlz5jB16lR27txJvXr1CA8PJzk5mSlTprBo0SLq1695Q82O9OjTgKByjwOBjPOcs0lrXQIcVErtw0j8sVrrDACtdbJSahXQCUhyOEIPHxj6ptG7//kh+HQQ9H4c+j4Dbh4Ov4wQwnk42vOuKlqf25c1xMTEsGbNGn777TdGjx7NU089xb333sv27dtZvHgxM2fO5Ntvv+Wzzz6r5ogvzJEefSwQoZQKU0p5ACOBc2fP/Az0B1BKNcUYyklWSjVSSnmWO94L2MPlCO8HkzdAh7tg7b/gkwGQufuyXkoIIS4kJiaGBQsWUFZWRlZWFmvWrKFr166kpKTg6+vLAw88wP3338/WrVs5fvw4NpuN4cOH849//IOtW7eaHf5fXLRHr7UuVUo9DCzGGH//TGu9Wyk1DYjTWi+0P3edUmoPUAY8pbXOVkr1BD5UStkwfqm8Xn62ziXzagC3fABtboRfHoEP+0L/v0GvR8HF9bJfVgghyrv11lvZuHEjHTp0QCnFG2+8gZ+fH1988QVvvvkm7u7u1K1bl7lz55Kens64ceOw2WwAvPbaayZH/1eqoj9RzBIdHa0d2njk9HH49THYuxBadIab3wO/9lUfoBCiSuzdu5e2bduaHYZTON+/lVIq3n4/9C9q3spYR/k0hTvmwvBPIfcwfNQXlk2FkgKzIxNCiBrFeRM9gFIQOQIejoVr7oR1b8MH3SFphdmRCSFEjeHcif4s78bG2P2YX0C5wpe3GsM6RflmRyaEEKazRqI/KywGJm2AnlMgbg7M7gUpG82OSgghTGWtRA/GqtrrXoFx/wGtYc71sOQFKJFda4QQtZP1Ev1ZIT2N3n3UWNjwLszuDSkbzI5KCCGqnXUTPYBnXbhpBoz+CcqKjd79wkeg4ITZkQkhRLWxdqI/q+UAmLwRejwM276EWb2kZo4Q4opcqHb9oUOHaN++5qzrqR2JHoyaOYNfhfHLjVW0n14HS1+C4jNmRyaEEFXKkaJm1hLQGR5cY9ygXT8D9vwMN75t9PqFEDXD78/C0Z2V+5p+kXD96xU+/cwzzxASEsLkyZMBmDp1Kkop1qxZw4kTJygpKeGVV15h2LBzt+O4sMLCQiZNmkRcXBxubm5Mnz6d/v37s3v3bsaNG0dxcTE2m40ffviBFi1acMcdd5CWlkZZWRkvvPACd9555xU1G2pTj768Oo1g2Psw5ldwcTPm3f/4oFFWQQhRK40cOfK/G4wAfPvtt4wbN46ffvqJrVu3snLlSp544okKK1tWZObMmQDs3LmTb775hjFjxlBYWMjs2bN59NFHSUhIIC4ujsDAQBYtWkSLFi3Yvn07u3btYsiQIZXSttrXoy8vrA9MXA9r3zJW1R5YAoP/DzqMNFbdCiHMcYGed1Xp1KkTx44dIyMjg6ysLBo1aoS/vz+PPfYYa9aswcXFhfT0dDIzM/Hz83P4ddetW8eUKVMAaNOmDSEhIezfv58ePXrw6quvkpaWxm233UZERASRkZE8+eSTPPPMM9x444306dOnUtpWO3v05bl7wYDnjQ1OmkbAzxNh7jDIdrxkvhDCGkaMGMH333/PggULGDlyJPPmzSMrK4v4+HgSEhJo3rw5hYWXtianor8ARo0axcKFC6lTpw6DBw9mxYoVtG7dmvj4eCIjI3nuueeYNm1aZTRLEv1/+baFcYvghumQsQ1mdoNFf4MzOWZHJoSoJiNHjmT+/Pl8//33jBgxgpMnT+Lr64u7uzsrV64kJSXlkl8zJiaGefPmAbB//34OHz7MVVddRXJyMuHh4TzyyCPcfPPN7Nixg4yMDLy9vbnnnnt48sknK622fe0eujmXiwt0ud/YzWrFK7DpA0iYB32fNrYzdHU3O0IhRBVq164deXl5BAQE4O/vz913381NN91EdHQ0HTt2pE2bNpf8mpMnT2bixIlERkbi5ubG559/jqenJwsWLOCrr77C3d0dPz8/XnzxRWJjY3nqqadwcXHB3d2dWbNmVUq7nLcefXU4uguWvmBUw/SLNGret+hkdlRCWJLUo3dc7alHXx382hurau/4EvKz4OMBsOTvMvdeCOFUZOjGEVffbFTGXPoibHgP9v4CN86Alv3NjkwIYaKdO3cyevToPx3z9PRk8+bNJkV0fpLoHVWnIdz8LkTeDr88Cl/eAh3vNiplejc2OzohLEFrjXKiqc2RkZEkJCRU63teznC7DN1cqrA+MGk99H4cts+H97vAtq/AvjGwEOLyeHl5kZ2dfVmJrLbQWpOdnY2Xl9clXSc3Y6/E0Z3w2xOQuhmCusGtH0LjMLOjEsIplZSUkJaWdsnz1GsbLy8vAgMDcXf/8yzAC92MlUR/pWw22P4NLH4ONDDwBYgaB64yKiaEqD4y66YqubhAp7vhwbXQogP850n4qJ9sciKEqDEk0VeWRiFw70K4/QsozDU2Ofn+fjiZbnZkQohazqFEr5QaopTap5RKVEo9W8E5dyil9iildiulvi53fIxS6oD9a0xlBV4jKQXtboGHtkDM08Y0zHc7wX+ehlNHzI5OCFFLXXSMXinlCuwHBgFpQCxwl9Z6T7lzIoBvgQFa6xNKKV+t9TGlVGMgDojGGMGOB6K01hXu5ed0Y/QXciIF1v4Lts0DNy+4dip0GW8M9wghRCW60jH6rkCi1jpZa10MzAfOrbz/ADDzbALXWh+zHx8MLNVa59ifWwpUToFlZ9AoxCibMCUOgrvD70/B5zdIZUwhRLVyJNEHAKnlHqfZj5XXGmitlFqvlNqklBpyCdeilJqglIpTSsVlZllw84/G4XDPDzDsAzi2G2b1NFbY2srMjkwIUQs4kujPt0zt3PEeNyAC6AfcBXyilGro4LVorT/SWkdrraOzit2ZuTKR4lKLLUBSypidM3mzsW3hkr/Dp4Mgc7fZkQkhLM6RRJ8GBJV7HAhknOecf2utS7TWB4F9GInfkWv/pH4dd95cvI+b3lvH1sMVDuU7r/r+MPJrGP4pnDgEs/sYN2sLLNhWIUSN4EiijwUilFJhSikPYCSw8Jxzfgb6AyilmmIM5SQDi4HrlFKNlFKNgOvsxyoU3NibT+6N5lRhCcNnbeDFf+8ir7Dk0lpV0ykFkSPg4TiIHgexH8OMa2Dla1BSYHZ0QgiLuWii11qXAg9jJOi9wLda691KqWlKqZvtpy0GspVSe4CVwFNa62ytdQ7wD4xfFrHANPuxC7r26uYsfbwvY3qE8uWmFAZNX8OS3Ucvr4U1mXdjuOEtY7FVy/6w+nX4oDskfCO1c4QQlabGl0BISM3l2R928MfRPIa08+PlYe1oXv/SCvo4jeTVsOR5o4ZOi85w43TZ6EQI4RCnr3VTUmbjk7UHmbFsPx6uLjx9fRvu7hqMi4vzlDN1mNaw41vjZu3pLOg8Gvr/Heo1NzsyIUQN5vSJ/qxDx0/z/M87WZ+YTVRII167LZLWzetVc4TVpPAkrH4DNn8Irh7Q5zHo8TC41zE7MiFEDWSZRA9GPeYft6bzym97yC8qZVLflkzu3wovd9dqjLIaZSfBspeMcgr1A2Hgi8bmJ7K6VghRjqUS/VnZ+UW8+tteftyWTnhTH/7vtki6hzephghNkrIBFv8NMrZBQBTcMB1adDQ7KiFEDWHJMsVN6noy/c6OzL2vKyU2GyM/2sQz3+8g90yx2aFVjZCeMH6FsbnJyTT4uD/8/iwU5ZkdmRCihnPaHn15BcVlzFi+n0/WHqSRtzsv3dSOG6/xd6q9Jy9JQS6s+AfEfgr1/OH6f0Lbm4z5+UKIWsmSPfry6ni48tz1bVn4cC9aNKzDlG+2cd/nsaSdOGN2aFWjTkNj/v34ZeDTBL4dDd+MNKplCiHEOSzRoy+vzKb5YsMh/rVkHwCPDIzgvl5heLhZ4nfaX5WVwubZsPL/AG1sWt59InhadDaSEOK8LHkz9mLScwt46d+7WbY3k5bNfHj55vb0jmhaCRHWUCfTYNGzxuwc7ybQ61Ho8gB4eJsdmRCiGtTKRH/Wij8ymbpwD4dzznBDpD9/v7Et/g0sPBc9LR5WvgpJy8HHF/o8AVFjwd2iq4mFEEAtT/QAhSVlfLQmmZkrE3F1UUwZEMH9vS08nAOQstFI+IfWQv0AI+F3Gg1uHmZHJoSoArU+0Z+VmnOGab/uYemeTMKb+TDN6sM5YNTPWfkqpG6GhsHQdQJ0uAt8LN5uIWoZSfTnWPnHMab+spuUbGM45/kb2tKioYWHc7SGxGWw+p+QFgteDWDQNOh0r6ywFcIiJNGfR/nhHBelmDKwFeN7h1t7OAcgcw/8/rQxpBPYBa59GUJ7mR2VEOIKSaK/gD8N5zT14YUbr6Z/G99qe39TaA0JXxuLrvKOQKtroe+zENTF7MiEEJdJEr0DVu47xrRf9nDw+GkGtPHlhRuvJqypT7XHUa1KCmDLx7DubSjIgfB+cN0r4BdpdmRCiEskid5BxaU25qw/yLvLD1BcZuP+3uE8PKAVdT3dTImn2hTlQ9xnsH6GUV6h1yPQ9xkpiSyEE5FEf4mOnSrkn4v28cPWNHzrefLc0Dbc0jHAurVzzjqTA0tfgG1fQaMwuGmG0csXQtR4lq91U9l863vx1h0d+HFyT/waePHYgu0Mn7WBhNRcs0OrWt6NYdhMGPOLUSBt7jD48UE4dcTsyIQQV0B69Bdhs2m+j0/jjcV/cDy/mJs7tODpIVcR2MjipQVKCmDNm7DhPXBxg972Ha6kpIIQNZIM3VSC/KJSZq9K4uO1yWjgvl5hTO7fkvpe7maHVrVyDsLSF2HvQmOF7bVTof0ImX8vRA0jib4SZeQW8K/F+/hxWzqNfTx47NoI7uoajJurxRPfofWw+Dk4st3Y4WrI6xDU1eyohBB2kuirwM60k7zy2x42H8yhZTMf/ja0LQPa+Fr7hq3NBjvmw7KXIf8odLrHSPhSElkI00miryJaa5buyeS13//g4PHT9GzZhOdvaEu7Fg3MDq1qFeXbx+/fhTqNoOuD0PUB42auEMIUkuirWEmZjXmbUnhn+QFyC0oY3jmQJ6+7Cr8GFi8NnBZv1M85sBg8G8DAF6DzGKmQKYQJrjjRK6WGAO8ArsAnWuvXz3l+LPAmkG4/9L7W+hP7c2XATvvxw1rrmy/0Xs6Y6M86WVDCzJWJfL7+EK4uigdiwnkwJhwfqy+4ytxtbHpycI2xh233yUYNfK/6ZkcmRK1xRYleKeUK7AcGAWlALHCX1npPuXPGAtFa64fPc32+1rquo8E6c6I/63D2Gf65+A9+23EE33qePHFda0ZEBeHqYuHxe60haYWxuvbgGqOH3+V+Y0qmTxOzoxPC8q50wVRXIFFrnay1LgbmA8MqM0CrCW7izcxRnflhUk8CGtXhmR92csO7a1l7IMvs0KqOUtBqoLHY6oEVEN7XqKHzfhRs/hCKLbpRuxBOwJFEHwCklnucZj92ruFKqR1Kqe+VUkHljnsppeKUUpuUUrec7w2UUhPs58RlZVknGUaFNOLHST15f1QnTheXMvrTLYybs4UDmXlmh1a1AqLgzi9h0gbwbWeURZ4RCevfMTYzF0JUK0eGbm4HBmutx9sfjwa6aq2nlDunCZCvtS5SSk0E7tBaD7A/10JrnaGUCgdWAAO11kkVvZ8Vhm7Op6i0jC82HOK9FYmcLirlzi7BPHZtBL71LX7DVms4vBHWvmVsfuIXadTAbznA+CtACFEprnToJg0o30MPBDLKn6C1ztZaF9kffgxElXsuw/49GVgFdHI4cgvxdHNlQkxLVj/Vn3t7hPJ9fCp931zF9KX7yS+ycC9XKQjpCff8AHfMhYKT8NVtMGeosQhLCFHlHEn0sUCEUipMKeUBjAQWlj9BKeVf7uHNwF778UZKKU/7z02BXsAearHGPh5Mvbkdyx7vy8C2vry7/AD93lzJ3I2HKC61mR1e1bp6GEyJg6H/gpxk+HwofDUcju68+LVCiMvm6PTKocAMjOmVn2mtX1VKTQPitNYLlVKvYST4UiAHmKS1/kMp1RP4ELBh/FKZobX+9ELvZdWhm4okpOby2n/2svlgDsGNvXniutbcdE0LXKw8Qwf+t+nJ2reg8CRE3g4DnodGoWZHJoRTkgVTNZzWmlX7s3hj0T72HjlFW//6PD3kKvq1bmbtkgpgbHSyfgZsmgW2MugyHmKeBJ+mZkcmhFORRO8kbDbNLzsyeGvJfg7nnKFbWGOeHnIVUSG1oLTAyXRY/bqx6Ym7D/R6FHpMBg+Lb+coRCWRRO9kikttzI89zLvLEzmeX8SANr48cV1r69fQAcjaB8unwR+/go8v9H1ayioI4QBJ9E7qTHEpn284xOxVSZwqLOXGa/x5bFBrWjZzeKGx8zq8GZZNhcMboGEwDP4/aHuT2VEJUWNJondyJwtK+HhNMp+tP0hhSRkjogJ5ZGCE9Xe50hqSlsPSlyBzF4T2MUoqRFwnG58IcQ5J9BZxPL+ID1Ym8dWmFABGdQtmcv+W+Naz+KKrshKjjMLGmZCXYay2veFfxvx8IQQgid5y0nMLeG/5Ab6LT8PD1YVxvUJ5MKYlDbwtvq1hWQns/hmWvwwnU+GakdD/b9AoxOzIhDCdJHqLOnj8NG8v3c/C7RnU83LjwZhwxvUKs35Z5OLTsOZfsPF9Y3in82jo8yQ0OF8JJiFqB0n0Frf3yCneWrKfZXszaeLjwUP9WzGqWzBe7q5mh1a1TqYbC662zjVKLUSNgz6PQz0/syMTotpJoq8lth4+wb8W72NDUjb+Dbx4dGAEI6ICrb9xee5hY2vDbfPA1d24YRvzJLjXMTsyIaqNJPpaZn3icd5cvI+E1FxCm3gzqV9Lbu0UiIebxRN+TjKsfA12fguNw+GG6dCyv9lRCVEtJNHXQlprlu09xoxl+9mdcQq/+l6M7xPGXV2DrT+Gn7wKfn3MSPwRg6HXIxDa2+yohKhSkuhrMa01aw8cZ9aqJDYmZ9OgjjsP9AljfJ9wa4/hlxTCpg9gw3tQkANhMTBwKgRGXfRSIZyRJHoBwLbDJ5i5MollezNp0cCLp4Zcxc0dAqy9l21JAcR/bszSOXMc2twIA14A3zZmRyZEpZJEL/5kc3I2r/y2l53pJ2nlW5dHB0ZwQ6S/tUsjF+XBRnsPv+Q0RN5h3LBtGmF2ZEJUCkn04i9sNs2i3UeZsWw/+zPzad28Lg8PMBK+pXv4p7Nh/duw5RMoLYT2wyHmKenhC6cniV5UyGbT/LbzCO8sP0DisXzCm/owuX8rhnVsgbuVp2XmZxkLrrZ8DCVn4Jo7of9zsvGJcFqS6MVFne3hv7cikb1HThHaxJvHBtWC3a5OZxsbn2z5yNj4JGosdJ8ETVqaHZkQl0QSvXDY2WmZby3Zxx9H82jjV4/HBrXm2rbNrT2kcyrDWHS1dS7YSo1pmQP+Dv7XmB2ZEA6RRC8umc2m+XXnEaYv2ceh7DMENa7DIwMiuLVTgLVX2p46Atu+NKZmFp6EjndDzynQ7CqzIxPigiTRi8tWUmZj6Z5MZq9OYkfaScKb+fDIgAhuvMbf2gm/4ASset2YmllaCFcNNXr4zduZHZkQ5yWJXlwxrTWLd2cyfek+9mfmE9rEm8n9W3FrpwBr37Q9fRxiPzGmZhadgo6joN9z0DDI7MiE+BNJ9KLS2GyaJXuMm7a7M04R2KgOk/u1YkSUxWvpnMmBddNh80fG43a3yjx8UaNIoheVTmvNyn3HeHd5IgmpuQQ0rMOUAa0YHhVo7R5+7mFY/w5sX2AM6fR82KiF71kL9vEVNZokelFltNas2p/FjKX72Z52kqDGdZjUtxXDowLwdLNwLZ38LFj2EiTMA88GED0Wej8GdRqZHZmopS6U6B3qeimlhiil9imlEpVSz57n+bFKqSylVIL9a3y558YopQ7Yv8ZcfjNETaSUov9Vvvz8UC8+HRNNI28P/vbTTvq+sYpP1x3kTHGp2SFWjbrN4JYPYPwKaDUQ1r8L73Q0evtFeWZHJ8SfXLRHr5RyBfYDg4A0IBa4S2u9p9w5Y4ForfXD51zbGIgDogENxANRWusTFb2f9Oidm9aadYnHeX9FIpsP5tDYx4P7e4cxukcI9b0svKft0V2w9EVIWg5eDaDLeGMDFO/GZkcmaokr7dF3BRK11sla62JgPjDMwfceDCzVWufYk/tSYIiD1wonpJSiT0QzFjzYg+8n9uCawAa8uXgfvV5bwRuL/uDYqUKzQ6wafu1h9I8wfrlREnntdKOHv/h5yE01OzpRyzmS6AOA8v9T0+zHzjVcKbVDKfW9Uurs3DOHrlVKTVBKxSml4rKyshwMXdR00aGN+XxcV36d0ps+rZsya3USfd5YyRuL/iDndLHZ4VWNwGi48yuYtAFaDYDNs+G9KFg2FQpPmR2dqKUcSfTnW/d+7njPL0Co1voaYBnwxSVci9b6I611tNY6ulmzZg6EJJxJ+4AGfHB3FCuf6MeQ9n58sCqJXq+vYOrC3aTnFpgdXtVofjXc/jk8kgBXD4N1b8O7nSD2Uyiz6H0LUWM5kujTgPKrQwKBjPInaK2ztdZF9ocfA1GOXitqj9CmPrwzshNLH4vhxmv8mbc5hX5vruS5H3eSmnPG7PCqRsMgGP4xPLACmraG3x6H2b1g3yKoYTPehHU5cjPWDeNm7EAgHeNm7Cit9e5y5/hrrY/Yf74VeEZr3d1+MzYe6Gw/dSvGzdicit5PbsbWHhm5BcxalcSC2FRsWnNb5wAm92tFaFMfs0OrGlrDH7/B0heM/WybtYGBL8FV14OycME4US2ueB69UmooMANwBT7TWr+qlJoGxGmtFyqlXgNuBkqBHGCS1voP+7X3AX+zv9SrWus5F3ovSfS1z9GThcxencQ3Ww5TVGqjT0RTHurfiu7hTcwOrWqUFsOuH4yVtsf3Q3g/uHYqtOhkblzCqcmCKeEUjuUVMn9LKnM3pnA8v4iuoY2ZMrAVvVs1RVmxx1tWAnGfwcr/g8JcaDXI2O0quJvZkQknJIleOJXCkjLmbznM7NXJHD1VSMeghkwZ0IoBbXytmfALT9kLp70PZ7IhtI+R8MNiZEhHOEwSvXBKRaVlfB+fxgcrk0jPLaCNXz0m92/F0PZ+1iyRXHzaKIu8/l3IPwpB3WHIaxDQ+aKXCiGJXji1kjIbv2zP4INVSSQeyyekiTcPxrS0bj2dkkJj85PVb8DpLIgaAwNeBB+L3rMQlUISvbAEo0RyJrNWJbI97SS+9TwZ3yeMUd1CqOvpZnZ4la/wpJHsN80Cr/pG0bTo+6VSpjgvSfTCUrTWrE/M5oNViWxIyqZBHXfG9AhhbK8wGvt4mB1e5Tu2F5b8HRKXgXcTo4ZO1wfAs57ZkYkaRBK9sKyE1Fw+WJnIkj2Z1HF35a6uwTwQE4Z/gzpmh1b5UmNhzRtwYIlRDrn7Q9BtglFETdR6kuiF5R3IzGPW6iT+nZCBi4JbOwUwsW9LwptZcJgjPd4Y0tm/yEj4/Z+HqHHgasHhK+EwSfSi1kjNOcPHa5NZEJtKcZmN69v7MblfK9oHWLDXm7HNKI18cA34Xg19n4a2w8DFgjOSxEVJohe1TlZeEXPWH+TLjSnkFZX+d7Vtt7DG1pqLrzXs/cWojpmTBAHRxirb0N4yB7+WkUQvaq1ThSV8tSmFz9Yd5Hh+MZ2DGzK5n7H4ysXFQonQVgY7vzNu2p7OAt920OMhuOZOGdKpJSTRi1qvsKSM7+JSmb06mfTcAq5qXo9J/Vpy4zX+1lp8VVIAO7+HzR9C5k5oHA59n4XIEeBiwTUH4r8k0Qthd3bx1axVSRw4lk9Q4zpMiGnJ7VGBeLlbKBFqDfv+AytfMxJ+09bQ99iF/2UAABbVSURBVBlod5uM4VuUJHohzmGzaZbtzeSDVUkkpObS2MeDwe38eHhAKwIaWmhqps0Gf/xiJPysvdCsLfScAu2Hg7uX2dGJSiSJXogKaK3ZmJzN15sPs2xvJi5KMbJLMGN7hhLcxNvs8CqPzQZ7foLVbxoJ37spRN9nfNX3Nzs6UQkk0QvhgLQTZ3hz8T5+23GEMq0Z2KY5k/q1JCqkkdmhVR6tIXmVMYa/f5Exbt9+uFFewbet2dGJKyCJXohLcPRkIV9tSuHrLYfJOV3M0Eg/JvVtRWSgxebiZyfBlo9g61woOQMRg+GaO4w9bl3dzY5OXCJJ9EJchjPFpcxencycdQfJKyqlV6smPBjTkj4RFtsI5UyO0cPf+gXkHYEGwdD7/0Gn0eBmwdpBFiWJXogrkFdYwjdbDvPpuoNkniqirX99JvYN54ZIi03NtNmMOjpr3oT0OGgYAgNflJk6TkISvRCVoLjUxs8J6Xy0JpnEY/kENKzD+D5h3NklCG8PCy1K0hoSlxurbTN3gn8HuPZlaNnf7MjEBUiiF6IS2WyalfuO8eHqZLYcyqGhtzv3dg/h3p6hNK3raXZ4lcdmM1bbrngFTh6GlgOMhO9/jdmRifOQRC9EFYlPOcFHa5JYsicTD1cXbo8OZHzvcEKb+pgdWuUpKYS4T40hnYITEHkH9HsWmrQ0OzJRjiR6IapYUlY+n6xN5of4dEptNq5v78+EmHA6BDU0O7TKU5AL698xdrwqK4KI6yBqLLQaJPV0agBJ9EJUk2OnCvl8wyG+3JRCXmEp3cMb82DflvRr3cw6M3XyjxmzdLZ9CfmZUD/AmKETNVYWX5lIEr0Q1Sy/qJT59pk6R04W0savHhNiwrmpQwvcrTJTp6zEWHQVNweSVoB7Heg+ydgEpWGQ2dHVOlec6JVSQ4B3AFfgE6316xWcNwL4DuiitY5TSoUCe4F99lM2aa0nXui9JNELKykutfHrjgw+XJ3Mvsw8WjTw4r7eYYzsGmytDc2zk2D5NNjzb+Nx6yEw6GVodpW5cdUiV5TolVKuwH5gEJAGxAJ3aa33nHNePeA3wAN4uFyi/1Vr3d7RYCXRCyvSWrNqfxYfrk5iU3IO9b3cuKd7CGN7heJbz0LFxXIPw9YvYcuHUJQPHUZCnyfkxm01uNJE3wOYqrUebH/8HIDW+rVzzpsBLAOeBJ6URC/E+SWk5vLRmiR+33UUdxcXhkcFML5POC2ttL/t6ePGLJ34z6GsGFoONJJ+mxuMIR5R6S6U6B0ZLAwAUss9TrMfK/8GnYAgrfWv57k+TCm1TSm1WinVp4IAJyil4pRScVlZWQ6EJITz6hjUkA/ujmLFE/24PTqQH7amc+301Tz4ZRxbD58wO7zK4dMUrv8nPLrDKJh2bC/8cD+82wliP4HiM2ZHWKs40qO/HRistR5vfzwa6Kq1nmJ/7AKsAMZqrQ8ppVbxvx69J1BXa52tlIoCfgbaaa1PVfR+0qMXtU1WXhFzNx5i7sYUThaU0DW0MRNiwq213aHNBgdXGXXx07ZAnUbGTdseDxm/FMQVq9KhG6VUAyAJyLdf4gfkADdrrePOea1V2H8JVPR+kuhFbXW6qJQFsal8uu4g6bkFRPjWZUJMOMM6BuDhZpGZOlrD4Y2w6QPY+yt4+ED/v0HXB2Uu/hW60kTvhnEzdiCQjnEzdpTWencF56/ifz36ZkCO1rpMKRUOrAUitdY5Fb2fJHpR25WU2fjPziPMXp3M3iOnaF7fk/t6hXFXt2Dqe1mofHDWfljyvFFIzb+DsdVhxHVSIvkyVcb0yqHADIzplZ9prV9VSk0D4rTWC885dxX/S/TDgWlAKVAGvKS1/uVC7yWJXgiD1pq1B47z4Zok1idmU8/TjVHdg7mvVxjN61tkpo7WsPsnWPw85GVA3ebQ8W7odI/M1LlEsmBKCCe3M+0kH65J4j87j+Dqori1UwATYsJp5VvP7NAqR1mp0bPf+oXxXdsguAfEPGnM2LHKquIqJIleCIs4nH2GT9Yl821cKoUlNq5t25yJfcOJDm1sdmiV51QG7PzeKLNwKg0Cu8LQN6BFJ7Mjq9Ek0QthMdn5RczdmMLcjYc4caaEzsENebBvSwa1bW6dmTqlxZAwD1a9ZtTXaXeLsfjKL9LsyGokSfRCWFRBcRnfxafy8dpkUnMKCGvqw7heoYyICrTOZigFubB+Bmz5BIrzjPIKfZ6EoC5mR1ajSKIXwuJKy2z8vuson647SEJqLo283bm3RyhjeobS2Mci+74WnIAtHxtTMwtOGGP4UWONzcxlta0keiFqk/iUHGatSmbZ3kzcXRWD2/nx2KDW1imxUJRvlFaI+xRyksGrIUSNgS4P1OqqmZLohaiFDmTm8c2WVBbEHuZMSRl9IpoxMSacHi2bWKM2vtZwaK3Ry//DXn2lzY3G7lfN25kbmwkk0QtRix3PL+LLjSl8s+Uwx/KK6BzckAkxLRl0dXNcrXLjNjfVqKETPweK8oyNUPo9C/VbmB1ZtZFEL4SgsKSM7+LT+HB1EmknCghsVIexPUO5o0uQdVbcnsmB1W9A7MegXCD6fqPEgld9syOrcpLohRD/VVpmY9neTD5bd4gth3Lw9nDl9qhAxvQMJdwq4/gnDsHa6bB1Lng3Nna+6vIA1LHQHr7nkEQvhDivXekn+Wz9QX7dfoTiMhv9r2rGfb3D6N2qqTXG8dPjYdXrxmpbj7rQ/jboPBYCo8yOrNJJohdCXNCxvELmbTrMvM0pHM8vJsK3LmN7hXJbp0DqeLiaHd6VO7LDWGm7+0coOWNMzez9OEQMskx5BUn0QgiHFJWW8ev2I3y2/iC7M07R0NudkV2CubdHCC0aWmCueuEp2P4NbHgPTqZC8/bGxihX3+L0ZZIl0QshLonWmthDJ5iz/iCLdx9FKcWQ9n7c1yuUzsGNnH9Yp6zEqKez7m04vg8ahULPR4zKme7OWRlUEr0Q4rKl5pzhy03G9My8wlKuCWzAfb3CGBrp7/wbothssO8/sG66MZ5ftzl0n2ysuHWyG7eS6IUQV+x0USk/bk1jzoZDJGedxreeJ6O7hzCqWzBN6nqaHd6VObv4au10SF4J7j7Q6W7oNtFp6uJLohdCVBqbTbP6QBZz1h9izf4sPNxcGNahBWN6htI+oIHZ4V25Iztg0yzY+R3YSuGqodBjMoT0qtE3biXRCyGqROKxPOasP8SPW9MpKCmjQ2ADJvVrxbVtfXFzdfJhnbyjxmrb2E+hIAcComDA3yG8f41M+JLohRBV6uSZEn5OSOeTdUa55KZ1PRkeFcD43uE0q+fkwzolBcZMnTVvGRuhBPeALuOh7U3gVnPaJoleCFEtSspsrPzjGN/Fp7Hij2N4urkwIiqQe3uEOP+2h6VFRtXMjTMhNwW8mxp720aNhcZhZkcniV4IUf0OHj/N+ysS+WV7BsVlNnq1asLo7qHOP6xjs0HyCoibA/t+N/a3bXUtdH3A+O5izgIzSfRCCNNk5xcxPzaVeZtSyDhZSEDDOozpGcKdXYJpUMfJi6mdyoD4L4yefv5RaBgCXe43qmd6V+8+vpLohRCmM4qpHWPO+oNsPmgUUxsRFciobsFc1byecy/CKiuBvb8YN29T1oObF7QfAV3HV9um5pLohRA1ytliar9sz6CkTNO0rgcT+7ZkXK8w56+Rn7nb2AxlxwKjrk5gF6NyZrtbqvTmrSR6IUSNlHO6mEW7jvL7riOsPXCckCbe3NMthNujA2no7eR73RbkGrN1Yj+B7ETj5m3ne6HrBKjvX+lvd8WJXik1BHgHcAU+0Vq/XsF5I4DvgC5a6zj7seeA+4Ey4BGt9eILvZckeiFqH601i3Yd5bP1B4k9dAJPNxeGdWzBvT0ssAjLZoODq4xe/v5FxrBO9H3GWH7j8Ep7mytK9EopV2A/MAhIA2KBu7TWe845rx7wG+ABPKy1jlNKXQ18A3QFWgDLgNZa67KK3k8SvRC1256MU3y5KYWftxmLsDoGNeSurkEM6xiAl7uTl0zOSYYVr8Ken43H0fdD32fAp8kVv/SVJvoewFSt9WD74+cAtNavnXPeDIxE/iTwpD3R/+lcpdRi+2ttrOj9JNELIQBOFpTwQ3wa8zankJR1Gr/6XozuEcLILkHOX1sn76ix5WH8HGNDlM73QrcHoWHwZb/khRK9I5NZA4DUco/T7MfKv0EnIEhr/eulXiuEEOfToI479/UOY9njfZk3vhvhzXx4c/E+ery2gscWJJCQmmt2iJevnh/cOB0mbTDm3m+aBe90gG9GQeIyY7inEjlSaf98t8D/+2eAUsoFeBsYe6nXlnuNCcAEgODgy/+NJoSwHqUUvVo1pVerpiQey+PLjSn8sDWdn7al0yGwAWN6hjI00t85h3V828LtcyA31bhpu+0r2PebMR8/epwxH9+n6RW/zRUP3SilGgBJQL79Ej8gB7gZY1xfhm6EEJUqr7CEH7em88VGo2RyI2937ogO4u5uIQQ38TY7vMtXWmTMx4+bAynrwKMe9HrUKLNQt9kFL73SMXo3jJuxA4F0jJuxo7TWuys4fxX/G6NvB3zN/27GLgci5GasEKIyaK3ZkJTNV5tSWLInE5vWxEQ0Y3T3EPq38XXuOfnH9sKyl2H/7+DiDm2GGgm/guqZF0r0Fx260VqXKqUeBhZjTK/8TGu9Wyk1DYjTWi+8wLW7lVLfAnuAUuChCyV5IYS4FOWHdY6eLOSbLYeZH3uY8XPjCGhYh1HdgrkjOsg5K2j6toVR8yFrH2ydCwnzYM+/oVkbYxesa+50eNtDWTAlhLCUkjIby/Zk8tXmFNYnZuPuqhjS3p/R3UPoEurE+92WFMLun4zqmZk7waeZ0cPvPAYaBsnKWCFE7ZR4LJ95m1P4Pj6NvMJSrmpej3u6B3NLpwDqeTlpQTWt4eAaI+EfWGJUy+w4CjXsfUn0Qoja60xxKb9sz+DLTSnsSj+Fj4crt3QK4J7uIbT1r292eJcv9zBseA/iv0C9mCWJXgghtNZsTzvJV5tS+GV7BkWlNqJDGjG6RwhD2vvh6eaEUzQBTh1BNWghiV4IIco7cbqY7+0rbw9ln6GJjwd3dAliVNdggho73xRNGaMXQogK2GyadYnH+WpTCsv2ZqKBAVf5ck/3EGJaN3OaKZqS6IUQwgEZuQXM33KYb2JTycorIqhxHUZ1DeGO6MAaX19HEr0QQlyC4lIbS/Yc5atNKWxKzsHD1YWhkX6M7hFC5+CaOUVTEr0QQlymA5l5zNt8mB/i08grKqWtf31jimbHAHw8HSkXVj0k0QshxBU6XVTKvxMy+GpTCnuOnKKupxvDOxtTNCOa1zM7PEn0QghRWbTWbD2cy7xNKfy64wjFZTa6hTXmnu4hDG7nh4ebI9XfK58keiGEqALZ+UV8Z5+imZpTQNO6nozsEsSdXYKqfYqmJHohhKhCNptm9YEs5m1KYfkfx9AaOgQ1ZGJMOIOubo6ba9X38iXRCyFENUk7cYZfdxxhQWwqB4+fplk9T27rHMAd0UG0bFa3yt5XEr0QQlSz0jIby/84xndxaazcd4wym6ZLaCPu7BLM0Eg/vD0qd8aOJHohhDDRsbxCftyazrexqSQfP009Tzdu7tiCO7sEERnQoFLm5UuiF0KIGkBrTeyhE8yPPcx/dh6hsMRGW//6jOwSxC0dA2jgffmlkyXRCyFEDXOyoISF2zNYEHuYXemn8HBz4fr2ftzZJYjuYU1wucQaO5LohRCiBtuVfpJv41L5aVs6eYWlhDTx5vaoQIZ1DHB4mqYkeiGEcAKFJWX8vusI87eksvlgDgBt/Orx+KDWDGzb/IKVNCXRCyGEkzmcfYZlezOZu/EQh7LP4N/Ai+GdAxkRFUhoU5+/nC+JXgghnFRxqY2lezL5Lj6VNfuzsGnoGtaY26MCGRrp/9/CapLohRDCAo6eLOSHrWl8H5/GweOn8fZw5YZIf0Z2DSI6tEmFib7m1NgUQghxQX4NvHiofysm92tJXMoJvotL5bcdR/guPu2C10mPXgghnNjpolJ+2pbO6B6hFfbozamnKYQQolL4eLpxT/eQC57jUKJXSg1RSu1TSiUqpZ49z/MTlVI7lVIJSql1Sqmr7cdDlVIF9uMJSqnZl9USIYQQl+2iY/RKKVdgJjAISANilVILtdZ7yp32tdZ6tv38m4HpwBD7c0la646VG7YQQghHOdKj7wokaq2TtdbFwHxgWPkTtNanyj30AWrWwL8QQtRijiT6ACC13OM0+7E/UUo9pJRKAt4AHin3VJhSaptSarVSqs/53kApNUEpFaeUisvKyrqE8IUQQlyMI4n+fGtu/9Jj11rP1Fq3BJ4B/m4/fAQI1lp3Ah4HvlZK1T/PtR9praO11tHNmjVzPHohhBAX5UiiTwOCyj0OBDIucP584BYArXWR1jrb/nM8kAS0vrxQhRBCXA5HEn0sEKGUClNKeQAjgYXlT1BKRZR7eANwwH68mf1mLkqpcCACSK6MwIUQQjjmorNutNalSqmHgcWAK/CZ1nq3UmoaEKe1Xgg8rJS6FigBTgBj7JfHANOUUqVAGTBRa51TFQ0RQghxfjVuZaxSKg/YZ3YcVagpcNzsIKqQtM+5SfucV4jW+rw3OWtirZt9FS3jtQKlVJy0z3lJ+5yb1dtXESmBIIQQFieJXgghLK4mJvqPzA6gikn7nJu0z7lZvX3nVeNuxgohhKhcNbFHL4QQohJJohdCCIurUYn+YnXvnZFS6lC5Wv1x9mONlVJLlVIH7N8bmR2no5RSnymljimldpU7dt72KMO79s9zh1Kqs3mRO6aC9k1VSqWX21dhaLnnnrO3b59SarA5UTtOKRWklFqplNqrlNqtlHrUftwSn+EF2meZz/CyaK1rxBfGqtskIBzwALYDV5sdVyW06xDQ9JxjbwDP2n9+Fvin2XFeQntigM7Arou1BxgK/I5RGK87sNns+C+zfVOBJ89z7tX2/6eeQJj9/6+r2W24SPv8gc72n+sB++3tsMRneIH2WeYzvJyvmtSjv2jdewsZBnxh//kL7EXgnIHWeg1wbhmLitozDJirDZuAhkop/+qJ9PJU0L6KDAPma6N430EgEeP/cY2ltT6itd5q/zkP2ItRdtwSn+EF2lcRp/sML0dNSvQO1b13QhpYopSKV0pNsB9rrrU+AsZ/TMDXtOgqR0XtsdJn+rB96OKzckNtTt0+pVQo0AnYjAU/w3PaBxb8DB1VkxK9Q3XvnVAvrXVn4HrgIaVUjNkBVSOrfKazgJZAR4w9Ft6yH3fa9iml6gI/AP9P/3mHuL+cep5jNb6N52mf5T7DS1GTEv2l1r13ClrrDPv3Y8BPGH8WZp7989f+/Zh5EVaKitpjic9Ua52ptS7TWtuAj/nfn/ZO2T6llDtGEpyntf7Rftgyn+H52me1z/BS1aREf9G6985GKeWjlKp39mfgOmAXRrvOlnIeA/zbnAgrTUXtWQjca5+50R04eXZ4wJmcMyZ9K8ZnCEb7RiqlPJVSYRj7LWyp7vguhVJKAZ8Ce7XW08s9ZYnPsKL2WekzvCxm3w0u/4Vxh38/xp3v582OpxLaE45xR387sPtsm4AmwHKMDVqWA43NjvUS2vQNxp++JRi9ofsrag/Gn8Uz7Z/nTiDa7Pgvs31f2uPfgZEY/Mud/7y9ffuA682O34H29cYYmtgBJNi/hlrlM7xA+yzzGV7Ol5RAEEIIi6tJQzdCCCGqgCR6IYSwOEn0QghhcZLohRDC4iTRCyGExUmiF0IIi5NEL4QQFvf/AW1LtsmyTHY2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss => error during training\n",
    "#val_loss=> erro during validation for nonseen data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3b685eb910>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics[['accuracy','val_accuracy']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38947364687919617, 0.96666664]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = len(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=4, activation=\"relu\", input_shape=[4,]))\n",
    "\n",
    "model.add(Dense(units=3, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/300\n",
      "150/150 [==============================] - 0s 2ms/sample - loss: 1.2964 - accuracy: 0.3333\n",
      "Epoch 2/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 1.2826 - accuracy: 0.3333\n",
      "Epoch 3/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 1.2681 - accuracy: 0.3333\n",
      "Epoch 4/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 1.2552 - accuracy: 0.3267\n",
      "Epoch 5/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 1.2422 - accuracy: 0.3267\n",
      "Epoch 6/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 1.2295 - accuracy: 0.3200\n",
      "Epoch 7/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 1.2171 - accuracy: 0.3133\n",
      "Epoch 8/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 1.2057 - accuracy: 0.3133\n",
      "Epoch 9/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 1.1939 - accuracy: 0.3133\n",
      "Epoch 10/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 1.1828 - accuracy: 0.3067\n",
      "Epoch 11/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 1.1713 - accuracy: 0.3067\n",
      "Epoch 12/300\n",
      "150/150 [==============================] - 0s 48us/sample - loss: 1.1602 - accuracy: 0.2933\n",
      "Epoch 13/300\n",
      "150/150 [==============================] - 0s 44us/sample - loss: 1.1494 - accuracy: 0.2800\n",
      "Epoch 14/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 1.1387 - accuracy: 0.2733\n",
      "Epoch 15/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 1.1287 - accuracy: 0.2733\n",
      "Epoch 16/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 1.1185 - accuracy: 0.2667\n",
      "Epoch 17/300\n",
      "150/150 [==============================] - 0s 51us/sample - loss: 1.1088 - accuracy: 0.2600\n",
      "Epoch 18/300\n",
      "150/150 [==============================] - 0s 52us/sample - loss: 1.0990 - accuracy: 0.2467\n",
      "Epoch 19/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 1.0891 - accuracy: 0.2400\n",
      "Epoch 20/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 1.0797 - accuracy: 0.2400\n",
      "Epoch 21/300\n",
      "150/150 [==============================] - 0s 48us/sample - loss: 1.0703 - accuracy: 0.2400\n",
      "Epoch 22/300\n",
      "150/150 [==============================] - 0s 49us/sample - loss: 1.0609 - accuracy: 0.2600\n",
      "Epoch 23/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 1.0520 - accuracy: 0.2667\n",
      "Epoch 24/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 1.0428 - accuracy: 0.3333\n",
      "Epoch 25/300\n",
      "150/150 [==============================] - 0s 46us/sample - loss: 1.0341 - accuracy: 0.4400\n",
      "Epoch 26/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 1.0256 - accuracy: 0.5333\n",
      "Epoch 27/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 1.0172 - accuracy: 0.5933\n",
      "Epoch 28/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 1.0092 - accuracy: 0.6133\n",
      "Epoch 29/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 1.0012 - accuracy: 0.6200\n",
      "Epoch 30/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.9933 - accuracy: 0.6667\n",
      "Epoch 31/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.9856 - accuracy: 0.6933\n",
      "Epoch 32/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.9778 - accuracy: 0.7067\n",
      "Epoch 33/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.9703 - accuracy: 0.7333\n",
      "Epoch 34/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.9626 - accuracy: 0.7333\n",
      "Epoch 35/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.9552 - accuracy: 0.7267\n",
      "Epoch 36/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 0.9480 - accuracy: 0.7267\n",
      "Epoch 37/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.9407 - accuracy: 0.7200\n",
      "Epoch 38/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.9336 - accuracy: 0.7133\n",
      "Epoch 39/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.9264 - accuracy: 0.7133\n",
      "Epoch 40/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.9193 - accuracy: 0.7067\n",
      "Epoch 41/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.9123 - accuracy: 0.7067\n",
      "Epoch 42/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.9052 - accuracy: 0.7067\n",
      "Epoch 43/300\n",
      "150/150 [==============================] - 0s 50us/sample - loss: 0.8985 - accuracy: 0.7067\n",
      "Epoch 44/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.8917 - accuracy: 0.6933\n",
      "Epoch 45/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.8848 - accuracy: 0.6800\n",
      "Epoch 46/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.8781 - accuracy: 0.6733\n",
      "Epoch 47/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.8714 - accuracy: 0.6733\n",
      "Epoch 48/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.8649 - accuracy: 0.6733\n",
      "Epoch 49/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.8584 - accuracy: 0.6800\n",
      "Epoch 50/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.8517 - accuracy: 0.6733\n",
      "Epoch 51/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 0.8452 - accuracy: 0.6733\n",
      "Epoch 52/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.8389 - accuracy: 0.6733\n",
      "Epoch 53/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.8324 - accuracy: 0.6733\n",
      "Epoch 54/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.8262 - accuracy: 0.6733\n",
      "Epoch 55/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.8200 - accuracy: 0.6800\n",
      "Epoch 56/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.8137 - accuracy: 0.6800\n",
      "Epoch 57/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.8077 - accuracy: 0.6800\n",
      "Epoch 58/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.8017 - accuracy: 0.6800\n",
      "Epoch 59/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.7957 - accuracy: 0.6800\n",
      "Epoch 60/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.7897 - accuracy: 0.6800\n",
      "Epoch 61/300\n",
      "150/150 [==============================] - 0s 51us/sample - loss: 0.7842 - accuracy: 0.6800\n",
      "Epoch 62/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.7780 - accuracy: 0.6800\n",
      "Epoch 63/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.7723 - accuracy: 0.6800\n",
      "Epoch 64/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.7667 - accuracy: 0.6800\n",
      "Epoch 65/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.7610 - accuracy: 0.6800\n",
      "Epoch 66/300\n",
      "150/150 [==============================] - 0s 54us/sample - loss: 0.7555 - accuracy: 0.6800\n",
      "Epoch 67/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.7500 - accuracy: 0.6800\n",
      "Epoch 68/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.7446 - accuracy: 0.6800\n",
      "Epoch 69/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.7394 - accuracy: 0.6867\n",
      "Epoch 70/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.7340 - accuracy: 0.6867\n",
      "Epoch 71/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.7287 - accuracy: 0.6867\n",
      "Epoch 72/300\n",
      "150/150 [==============================] - 0s 130us/sample - loss: 0.7236 - accuracy: 0.6867\n",
      "Epoch 73/300\n",
      "150/150 [==============================] - 0s 101us/sample - loss: 0.7183 - accuracy: 0.6867\n",
      "Epoch 74/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.7134 - accuracy: 0.6867\n",
      "Epoch 75/300\n",
      "150/150 [==============================] - 0s 50us/sample - loss: 0.7083 - accuracy: 0.6867\n",
      "Epoch 76/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.7034 - accuracy: 0.6867\n",
      "Epoch 77/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6985 - accuracy: 0.6867\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6937 - accuracy: 0.6867\n",
      "Epoch 79/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.6890 - accuracy: 0.6867\n",
      "Epoch 80/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6843 - accuracy: 0.6867\n",
      "Epoch 81/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.6797 - accuracy: 0.6867\n",
      "Epoch 82/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.6752 - accuracy: 0.6867\n",
      "Epoch 83/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.6707 - accuracy: 0.6867\n",
      "Epoch 84/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.6662 - accuracy: 0.6867\n",
      "Epoch 85/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.6619 - accuracy: 0.6867\n",
      "Epoch 86/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.6576 - accuracy: 0.6867\n",
      "Epoch 87/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.6533 - accuracy: 0.6867\n",
      "Epoch 88/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 0.6491 - accuracy: 0.6867\n",
      "Epoch 89/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.6449 - accuracy: 0.6933\n",
      "Epoch 90/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.6408 - accuracy: 0.7067\n",
      "Epoch 91/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.6368 - accuracy: 0.7067\n",
      "Epoch 92/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.6327 - accuracy: 0.7067\n",
      "Epoch 93/300\n",
      "150/150 [==============================] - 0s 57us/sample - loss: 0.6289 - accuracy: 0.7067\n",
      "Epoch 94/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.6250 - accuracy: 0.7067\n",
      "Epoch 95/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.6213 - accuracy: 0.7133\n",
      "Epoch 96/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.6175 - accuracy: 0.7133\n",
      "Epoch 97/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6138 - accuracy: 0.7133\n",
      "Epoch 98/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.6101 - accuracy: 0.7133\n",
      "Epoch 99/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.6066 - accuracy: 0.7133\n",
      "Epoch 100/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.6030 - accuracy: 0.7133\n",
      "Epoch 101/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5996 - accuracy: 0.7133\n",
      "Epoch 102/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5961 - accuracy: 0.7200\n",
      "Epoch 103/300\n",
      "150/150 [==============================] - 0s 56us/sample - loss: 0.5928 - accuracy: 0.7400\n",
      "Epoch 104/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.5895 - accuracy: 0.7467\n",
      "Epoch 105/300\n",
      "150/150 [==============================] - 0s 55us/sample - loss: 0.5862 - accuracy: 0.7467\n",
      "Epoch 106/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.5830 - accuracy: 0.7467\n",
      "Epoch 107/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.5799 - accuracy: 0.7400\n",
      "Epoch 108/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5768 - accuracy: 0.7400\n",
      "Epoch 109/300\n",
      "150/150 [==============================] - 0s 53us/sample - loss: 0.5736 - accuracy: 0.7467\n",
      "Epoch 110/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5707 - accuracy: 0.7467\n",
      "Epoch 111/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.5676 - accuracy: 0.7467\n",
      "Epoch 112/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.5647 - accuracy: 0.7667\n",
      "Epoch 113/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.5617 - accuracy: 0.7733\n",
      "Epoch 114/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.5589 - accuracy: 0.7733\n",
      "Epoch 115/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.5561 - accuracy: 0.7733\n",
      "Epoch 116/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5533 - accuracy: 0.7733\n",
      "Epoch 117/300\n",
      "150/150 [==============================] - 0s 51us/sample - loss: 0.5506 - accuracy: 0.7733\n",
      "Epoch 118/300\n",
      "150/150 [==============================] - 0s 138us/sample - loss: 0.5479 - accuracy: 0.7800\n",
      "Epoch 119/300\n",
      "150/150 [==============================] - 0s 95us/sample - loss: 0.5451 - accuracy: 0.7867\n",
      "Epoch 120/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.5426 - accuracy: 0.8000\n",
      "Epoch 121/300\n",
      "150/150 [==============================] - 0s 79us/sample - loss: 0.5400 - accuracy: 0.8000\n",
      "Epoch 122/300\n",
      "150/150 [==============================] - 0s 90us/sample - loss: 0.5374 - accuracy: 0.8000\n",
      "Epoch 123/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.5350 - accuracy: 0.8000\n",
      "Epoch 124/300\n",
      "150/150 [==============================] - 0s 50us/sample - loss: 0.5323 - accuracy: 0.8000\n",
      "Epoch 125/300\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.5298 - accuracy: 0.8000\n",
      "Epoch 126/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.5274 - accuracy: 0.8067\n",
      "Epoch 127/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.5251 - accuracy: 0.8133\n",
      "Epoch 128/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.5226 - accuracy: 0.8200\n",
      "Epoch 129/300\n",
      "150/150 [==============================] - 0s 103us/sample - loss: 0.5203 - accuracy: 0.8200\n",
      "Epoch 130/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.5180 - accuracy: 0.8200\n",
      "Epoch 131/300\n",
      "150/150 [==============================] - 0s 109us/sample - loss: 0.5158 - accuracy: 0.8133\n",
      "Epoch 132/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.5135 - accuracy: 0.8133\n",
      "Epoch 133/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.5112 - accuracy: 0.8133\n",
      "Epoch 134/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.5091 - accuracy: 0.8133\n",
      "Epoch 135/300\n",
      "150/150 [==============================] - 0s 52us/sample - loss: 0.5069 - accuracy: 0.8133\n",
      "Epoch 136/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.5047 - accuracy: 0.8133\n",
      "Epoch 137/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.5026 - accuracy: 0.8200\n",
      "Epoch 138/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.5005 - accuracy: 0.8267\n",
      "Epoch 139/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.4985 - accuracy: 0.8267\n",
      "Epoch 140/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.4964 - accuracy: 0.8333\n",
      "Epoch 141/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.4944 - accuracy: 0.8467\n",
      "Epoch 142/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.4924 - accuracy: 0.8467\n",
      "Epoch 143/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4903 - accuracy: 0.8600\n",
      "Epoch 144/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4885 - accuracy: 0.8600\n",
      "Epoch 145/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.4865 - accuracy: 0.8600\n",
      "Epoch 146/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4845 - accuracy: 0.8600\n",
      "Epoch 147/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4826 - accuracy: 0.8667\n",
      "Epoch 148/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.4807 - accuracy: 0.8667\n",
      "Epoch 149/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.4788 - accuracy: 0.8667\n",
      "Epoch 150/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.4770 - accuracy: 0.8667\n",
      "Epoch 151/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.4751 - accuracy: 0.8667\n",
      "Epoch 152/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.4732 - accuracy: 0.8667\n",
      "Epoch 153/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4715 - accuracy: 0.8733\n",
      "Epoch 154/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 0.4696 - accuracy: 0.8800\n",
      "Epoch 155/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4678 - accuracy: 0.8800\n",
      "Epoch 156/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4661 - accuracy: 0.8800\n",
      "Epoch 157/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4642 - accuracy: 0.8800\n",
      "Epoch 158/300\n",
      "150/150 [==============================] - 0s 70us/sample - loss: 0.4624 - accuracy: 0.8867\n",
      "Epoch 159/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4607 - accuracy: 0.8867\n",
      "Epoch 160/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.4590 - accuracy: 0.8933\n",
      "Epoch 161/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4573 - accuracy: 0.8933\n",
      "Epoch 162/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.4556 - accuracy: 0.8933\n",
      "Epoch 163/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.4539 - accuracy: 0.8933\n",
      "Epoch 164/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.4523 - accuracy: 0.9067\n",
      "Epoch 165/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.4505 - accuracy: 0.9067\n",
      "Epoch 166/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.4489 - accuracy: 0.9000\n",
      "Epoch 167/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.4473 - accuracy: 0.9067\n",
      "Epoch 168/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.4457 - accuracy: 0.9067\n",
      "Epoch 169/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.4440 - accuracy: 0.9133\n",
      "Epoch 170/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.4424 - accuracy: 0.9267\n",
      "Epoch 171/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.4409 - accuracy: 0.9267\n",
      "Epoch 172/300\n",
      "150/150 [==============================] - 0s 117us/sample - loss: 0.4392 - accuracy: 0.9267\n",
      "Epoch 173/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.4377 - accuracy: 0.9267\n",
      "Epoch 174/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.4361 - accuracy: 0.9333\n",
      "Epoch 175/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.4345 - accuracy: 0.9400\n",
      "Epoch 176/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.4330 - accuracy: 0.9400\n",
      "Epoch 177/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.4315 - accuracy: 0.9400\n",
      "Epoch 178/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.4300 - accuracy: 0.9400\n",
      "Epoch 179/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.4285 - accuracy: 0.9400\n",
      "Epoch 180/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.4269 - accuracy: 0.9400\n",
      "Epoch 181/300\n",
      "150/150 [==============================] - 0s 86us/sample - loss: 0.4255 - accuracy: 0.9400\n",
      "Epoch 182/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.4240 - accuracy: 0.9400\n",
      "Epoch 183/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.4225 - accuracy: 0.9400\n",
      "Epoch 184/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.4211 - accuracy: 0.9400\n",
      "Epoch 185/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.4197 - accuracy: 0.9400\n",
      "Epoch 186/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4182 - accuracy: 0.9400\n",
      "Epoch 187/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.4168 - accuracy: 0.9467\n",
      "Epoch 188/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.4153 - accuracy: 0.9467\n",
      "Epoch 189/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.4139 - accuracy: 0.9400\n",
      "Epoch 190/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.4124 - accuracy: 0.9400\n",
      "Epoch 191/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.4110 - accuracy: 0.9400\n",
      "Epoch 192/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.4097 - accuracy: 0.9400\n",
      "Epoch 193/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.4082 - accuracy: 0.9400\n",
      "Epoch 194/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.4070 - accuracy: 0.9400\n",
      "Epoch 195/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.4055 - accuracy: 0.9467\n",
      "Epoch 196/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.4043 - accuracy: 0.9400\n",
      "Epoch 197/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.4030 - accuracy: 0.9400\n",
      "Epoch 198/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.4016 - accuracy: 0.9400\n",
      "Epoch 199/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.4002 - accuracy: 0.9467\n",
      "Epoch 200/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3989 - accuracy: 0.9467\n",
      "Epoch 201/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3975 - accuracy: 0.9467\n",
      "Epoch 202/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.3962 - accuracy: 0.9467\n",
      "Epoch 203/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3950 - accuracy: 0.9467\n",
      "Epoch 204/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.3936 - accuracy: 0.9467\n",
      "Epoch 205/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.3923 - accuracy: 0.9467\n",
      "Epoch 206/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3911 - accuracy: 0.9467\n",
      "Epoch 207/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3898 - accuracy: 0.9467\n",
      "Epoch 208/300\n",
      "150/150 [==============================] - 0s 89us/sample - loss: 0.3886 - accuracy: 0.9467\n",
      "Epoch 209/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.3874 - accuracy: 0.9467\n",
      "Epoch 210/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3860 - accuracy: 0.9467\n",
      "Epoch 211/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3848 - accuracy: 0.9467\n",
      "Epoch 212/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3836 - accuracy: 0.9467\n",
      "Epoch 213/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3826 - accuracy: 0.9467\n",
      "Epoch 214/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3811 - accuracy: 0.9467\n",
      "Epoch 215/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3799 - accuracy: 0.9467\n",
      "Epoch 216/300\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.3787 - accuracy: 0.9467\n",
      "Epoch 217/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3775 - accuracy: 0.9467\n",
      "Epoch 218/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.3763 - accuracy: 0.9467\n",
      "Epoch 219/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.3751 - accuracy: 0.9467\n",
      "Epoch 220/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3739 - accuracy: 0.9533\n",
      "Epoch 221/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3728 - accuracy: 0.9467\n",
      "Epoch 222/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3715 - accuracy: 0.9467\n",
      "Epoch 223/300\n",
      "150/150 [==============================] - 0s 75us/sample - loss: 0.3704 - accuracy: 0.9467\n",
      "Epoch 224/300\n",
      "150/150 [==============================] - 0s 81us/sample - loss: 0.3693 - accuracy: 0.9467\n",
      "Epoch 225/300\n",
      "150/150 [==============================] - 0s 59us/sample - loss: 0.3680 - accuracy: 0.9467\n",
      "Epoch 226/300\n",
      "150/150 [==============================] - 0s 84us/sample - loss: 0.3669 - accuracy: 0.9533\n",
      "Epoch 227/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.3658 - accuracy: 0.9533\n",
      "Epoch 228/300\n",
      "150/150 [==============================] - 0s 62us/sample - loss: 0.3646 - accuracy: 0.9533\n",
      "Epoch 229/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.3635 - accuracy: 0.9600\n",
      "Epoch 230/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.3625 - accuracy: 0.9467\n",
      "Epoch 231/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.3612 - accuracy: 0.9600\n",
      "Epoch 232/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 60us/sample - loss: 0.3601 - accuracy: 0.9600\n",
      "Epoch 233/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3590 - accuracy: 0.9600\n",
      "Epoch 234/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3578 - accuracy: 0.9600\n",
      "Epoch 235/300\n",
      "150/150 [==============================] - 0s 49us/sample - loss: 0.3567 - accuracy: 0.9600\n",
      "Epoch 236/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.3556 - accuracy: 0.9600\n",
      "Epoch 237/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.3546 - accuracy: 0.9600\n",
      "Epoch 238/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3535 - accuracy: 0.9600\n",
      "Epoch 239/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.3524 - accuracy: 0.9600\n",
      "Epoch 240/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.3512 - accuracy: 0.9600\n",
      "Epoch 241/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.3502 - accuracy: 0.9600\n",
      "Epoch 242/300\n",
      "150/150 [==============================] - 0s 92us/sample - loss: 0.3493 - accuracy: 0.9600\n",
      "Epoch 243/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.3481 - accuracy: 0.9600\n",
      "Epoch 244/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.3471 - accuracy: 0.9600\n",
      "Epoch 245/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.3459 - accuracy: 0.9600\n",
      "Epoch 246/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.3448 - accuracy: 0.9600\n",
      "Epoch 247/300\n",
      "150/150 [==============================] - 0s 78us/sample - loss: 0.3438 - accuracy: 0.9600\n",
      "Epoch 248/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.3427 - accuracy: 0.9600\n",
      "Epoch 249/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.3417 - accuracy: 0.9600\n",
      "Epoch 250/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.3407 - accuracy: 0.9600\n",
      "Epoch 251/300\n",
      "150/150 [==============================] - 0s 64us/sample - loss: 0.3398 - accuracy: 0.9600\n",
      "Epoch 252/300\n",
      "150/150 [==============================] - 0s 61us/sample - loss: 0.3386 - accuracy: 0.9600\n",
      "Epoch 253/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.3376 - accuracy: 0.9600\n",
      "Epoch 254/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3366 - accuracy: 0.9600\n",
      "Epoch 255/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3355 - accuracy: 0.9600\n",
      "Epoch 256/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.3345 - accuracy: 0.9600\n",
      "Epoch 257/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.3335 - accuracy: 0.9600\n",
      "Epoch 258/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3325 - accuracy: 0.9600\n",
      "Epoch 259/300\n",
      "150/150 [==============================] - 0s 80us/sample - loss: 0.3315 - accuracy: 0.9600\n",
      "Epoch 260/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3304 - accuracy: 0.9600\n",
      "Epoch 261/300\n",
      "150/150 [==============================] - 0s 56us/sample - loss: 0.3295 - accuracy: 0.9600\n",
      "Epoch 262/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.3284 - accuracy: 0.9600\n",
      "Epoch 263/300\n",
      "150/150 [==============================] - 0s 99us/sample - loss: 0.3274 - accuracy: 0.9600\n",
      "Epoch 264/300\n",
      "150/150 [==============================] - 0s 74us/sample - loss: 0.3264 - accuracy: 0.9600\n",
      "Epoch 265/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.3253 - accuracy: 0.9600\n",
      "Epoch 266/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3249 - accuracy: 0.9600\n",
      "Epoch 267/300\n",
      "150/150 [==============================] - 0s 96us/sample - loss: 0.3234 - accuracy: 0.9600\n",
      "Epoch 268/300\n",
      "150/150 [==============================] - 0s 98us/sample - loss: 0.3224 - accuracy: 0.9600\n",
      "Epoch 269/300\n",
      "150/150 [==============================] - 0s 113us/sample - loss: 0.3214 - accuracy: 0.9600\n",
      "Epoch 270/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3204 - accuracy: 0.9600\n",
      "Epoch 271/300\n",
      "150/150 [==============================] - 0s 85us/sample - loss: 0.3194 - accuracy: 0.9600\n",
      "Epoch 272/300\n",
      "150/150 [==============================] - 0s 60us/sample - loss: 0.3185 - accuracy: 0.9600\n",
      "Epoch 273/300\n",
      "150/150 [==============================] - 0s 91us/sample - loss: 0.3175 - accuracy: 0.9667\n",
      "Epoch 274/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.3166 - accuracy: 0.9667\n",
      "Epoch 275/300\n",
      "150/150 [==============================] - 0s 69us/sample - loss: 0.3156 - accuracy: 0.9600\n",
      "Epoch 276/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3146 - accuracy: 0.9667\n",
      "Epoch 277/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.3136 - accuracy: 0.9667\n",
      "Epoch 278/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3127 - accuracy: 0.9667\n",
      "Epoch 279/300\n",
      "150/150 [==============================] - 0s 50us/sample - loss: 0.3117 - accuracy: 0.9667\n",
      "Epoch 280/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.3107 - accuracy: 0.9667\n",
      "Epoch 281/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3098 - accuracy: 0.9667\n",
      "Epoch 282/300\n",
      "150/150 [==============================] - 0s 67us/sample - loss: 0.3089 - accuracy: 0.9667\n",
      "Epoch 283/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.3079 - accuracy: 0.9667\n",
      "Epoch 284/300\n",
      "150/150 [==============================] - 0s 71us/sample - loss: 0.3070 - accuracy: 0.9667\n",
      "Epoch 285/300\n",
      "150/150 [==============================] - 0s 63us/sample - loss: 0.3061 - accuracy: 0.9667\n",
      "Epoch 286/300\n",
      "150/150 [==============================] - 0s 65us/sample - loss: 0.3051 - accuracy: 0.9667\n",
      "Epoch 287/300\n",
      "150/150 [==============================] - 0s 68us/sample - loss: 0.3041 - accuracy: 0.9667\n",
      "Epoch 288/300\n",
      "150/150 [==============================] - 0s 58us/sample - loss: 0.3032 - accuracy: 0.9667\n",
      "Epoch 289/300\n",
      "150/150 [==============================] - 0s 82us/sample - loss: 0.3022 - accuracy: 0.9667\n",
      "Epoch 290/300\n",
      "150/150 [==============================] - 0s 66us/sample - loss: 0.3013 - accuracy: 0.9667\n",
      "Epoch 291/300\n",
      "150/150 [==============================] - 0s 73us/sample - loss: 0.3004 - accuracy: 0.9667\n",
      "Epoch 292/300\n",
      "150/150 [==============================] - 0s 77us/sample - loss: 0.2995 - accuracy: 0.9667\n",
      "Epoch 293/300\n",
      "150/150 [==============================] - 0s 83us/sample - loss: 0.2985 - accuracy: 0.9667\n",
      "Epoch 294/300\n",
      "150/150 [==============================] - 0s 88us/sample - loss: 0.2977 - accuracy: 0.9667\n",
      "Epoch 295/300\n",
      "150/150 [==============================] - 0s 147us/sample - loss: 0.2967 - accuracy: 0.9667\n",
      "Epoch 296/300\n",
      "150/150 [==============================] - 0s 105us/sample - loss: 0.2959 - accuracy: 0.9667\n",
      "Epoch 297/300\n",
      "150/150 [==============================] - 0s 72us/sample - loss: 0.2950 - accuracy: 0.9667\n",
      "Epoch 298/300\n",
      "150/150 [==============================] - 0s 106us/sample - loss: 0.2940 - accuracy: 0.9667\n",
      "Epoch 299/300\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 0.2931 - accuracy: 0.9667\n",
      "Epoch 300/300\n",
      "150/150 [==============================] - 0s 76us/sample - loss: 0.2922 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b684c9410>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_X, y, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_iris_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['iris_scaler.pkl']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(scaler, 'iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_model = load_model('final_iris_model.h5')\n",
    "flower_scaler = joblib.load('iris_scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "flower_example = {\n",
    "    \"sepal_length\":5.1,\n",
    "    \"sepal_width\":3.5,\n",
    "    \"petal_length\":1.4,\n",
    "    \"petal_width\":0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-53-9230fc564a04>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-9230fc564a04>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0m\n\u001b[0;31m    flower = scaler.transform(flower)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def return_prediction(model,scaler,sample_json):\n",
    "    \n",
    "    s_len = sample_json[\"sepal_length\"]\n",
    "    s_wid = sample_json[\"sepal_width\"]\n",
    "    p_len = sample_json[\"petal_length\"]\n",
    "    p_wid = sample_json[\"petal_width\"]\n",
    "    \n",
    "    flower = [[s_len,s_wid,p_len,p_wid]]\n",
    "    \n",
    "    classes = np.array(['setosa', 'versicolor', 'virginica']\n",
    "    flower = scaler.transform(flower)\n",
    "    \n",
    "    class_ind = model.predict_classes(flower)\n",
    "    \n",
    "    return class_ind         \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
